{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ##                                 CLOUD BASED INSURANCE DATABASE             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABSTRACT:\n",
    "\n",
    "The idea behind this project is to build and Database that's almost simialar to the setup of an Insurance Service Provider's Enterprise Level Database/Data Repository. Since we are dealing with insurance data which holds sensitive personal details like address, age, sex, etc. obtaining a real world dataset is surreal, so, much of the data here are masked. We shall have also included an additional piece of code that shall be used to scrape the data from Twitter using Twitter API to allow our database to handle a real-world situation too. Here we are obtaining data from different sources and will be transforming them to fit into a uniform dataset template. This process is called as munging and post munging we will be cleaning the data to make sure that the data from those munged and cleaned dataset will be error free which can be loaded into a database.\n",
    "\n",
    "The key take-away from this project is not just to munge the data and load into database, but also hold the entire database in a public cloud platfrom like Amazon Web Services Platform. For the pupose of this project we have built the database in AWS RDS, a AWS Database service and configured the connections and setup to which we shall load the data post munging it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the packages we shall be using in this project to read the CSV file and munging the data and loading it into the MySQL Database\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Tweepy packages are used here to allow us to pull the data from Twitter API\n",
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import json\n",
    "from dateutil import parser\n",
    "#MySQLdb package is used here to load the munged data into Database.\n",
    "import MySQLdb\n",
    "import re\n",
    "from pandas.io import sql\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>age</th>\n",
       "      <th>age_category</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>STREET</th>\n",
       "      <th>...</th>\n",
       "      <th>Plan ID</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>Plan Marketing Name</th>\n",
       "      <th>Plan Type</th>\n",
       "      <th>policy_bind_date.1</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>report_available</th>\n",
       "      <th>claim_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>19</td>\n",
       "      <td>Minor</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1111</td>\n",
       "      <td>Country Club Rd</td>\n",
       "      <td>...</td>\n",
       "      <td>54192IN0020018</td>\n",
       "      <td>7/16/2002</td>\n",
       "      <td>CareSource Marketplace Low Deductible Silver D...</td>\n",
       "      <td>HMO</td>\n",
       "      <td>7/16/2002</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96200</td>\n",
       "      <td>YES</td>\n",
       "      <td>2/6/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>18</td>\n",
       "      <td>Minor</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>51</td>\n",
       "      <td>Parish Dr</td>\n",
       "      <td>...</td>\n",
       "      <td>42261UT0070001</td>\n",
       "      <td>11/28/2002</td>\n",
       "      <td>Healthy Premier Bronze w/3 Copays before Deduc...</td>\n",
       "      <td>EPO</td>\n",
       "      <td>11/28/2002</td>\n",
       "      <td>462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31200</td>\n",
       "      <td>?</td>\n",
       "      <td>1/18/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>28</td>\n",
       "      <td>Major</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>90</td>\n",
       "      <td>Stockings Brook Rd</td>\n",
       "      <td>...</td>\n",
       "      <td>40572FL0070006</td>\n",
       "      <td>5/12/2007</td>\n",
       "      <td>Oscar Classic Silver</td>\n",
       "      <td>EPO</td>\n",
       "      <td>5/12/2007</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14500</td>\n",
       "      <td>?</td>\n",
       "      <td>2/13/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>33</td>\n",
       "      <td>Major</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>99</td>\n",
       "      <td>Lamentation Dr</td>\n",
       "      <td>...</td>\n",
       "      <td>37903AR0070025</td>\n",
       "      <td>2/10/1998</td>\n",
       "      <td>Ambetter Balanced Care 7 (2020) (QualChoiceLife)</td>\n",
       "      <td>PPO</td>\n",
       "      <td>2/10/1998</td>\n",
       "      <td>384</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>NO</td>\n",
       "      <td>1/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>32</td>\n",
       "      <td>Major</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>207</td>\n",
       "      <td>Lamentation Dr</td>\n",
       "      <td>...</td>\n",
       "      <td>88380VA0720018</td>\n",
       "      <td>3/1/2012</td>\n",
       "      <td>Anthem HealthKeepers Bronze X 5250</td>\n",
       "      <td>HMO</td>\n",
       "      <td>3/1/2012</td>\n",
       "      <td>100</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>16500</td>\n",
       "      <td>YES</td>\n",
       "      <td>2/21/2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  age age_category     sex     bmi  SeniorCitizen  children  \\\n",
       "0  7590-VHVEG   19        Minor  female  27.900              0         0   \n",
       "1  5575-GNVDE   18        Minor    male  33.770              0         1   \n",
       "2  3668-QPYBK   28        Major    male  33.000              0         3   \n",
       "3  7795-CFOCW   33        Major    male  22.705              0         0   \n",
       "4  9237-HQITU   32        Major    male  28.880              0         0   \n",
       "\n",
       "  smoker  NUMBER              STREET  ...        Plan ID  policy_bind_date  \\\n",
       "0    yes    1111     Country Club Rd  ...  54192IN0020018        7/16/2002   \n",
       "1     no      51           Parish Dr  ...  42261UT0070001       11/28/2002   \n",
       "2     no      90  Stockings Brook Rd  ...  40572FL0070006        5/12/2007   \n",
       "3     no      99      Lamentation Dr  ...  37903AR0070025        2/10/1998   \n",
       "4     no     207      Lamentation Dr  ...  88380VA0720018         3/1/2012   \n",
       "\n",
       "                                 Plan Marketing Name Plan Type  \\\n",
       "0  CareSource Marketplace Low Deductible Silver D...       HMO   \n",
       "1  Healthy Premier Bronze w/3 Copays before Deduc...       EPO   \n",
       "2                               Oscar Classic Silver       EPO   \n",
       "3   Ambetter Balanced Care 7 (2020) (QualChoiceLife)       PPO   \n",
       "4                 Anthem HealthKeepers Bronze X 5250       HMO   \n",
       "\n",
       "  policy_bind_date.1 months_as_customer  umbrella_limit total_claim_amount  \\\n",
       "0          7/16/2002                  5             0.0              96200   \n",
       "1         11/28/2002                462             0.0              31200   \n",
       "2          5/12/2007                198             0.0              14500   \n",
       "3          2/10/1998                384       1000000.0               7500   \n",
       "4           3/1/2012                100       4000000.0              16500   \n",
       "\n",
       "  report_available  claim_date  \n",
       "0              YES    2/6/2015  \n",
       "1                ?   1/18/2015  \n",
       "2                ?   2/13/2015  \n",
       "3               NO   1/27/2015  \n",
       "4              YES   2/21/2015  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtaining the raw masked dataset.\n",
    "ins = pd.read_csv('insurancedata.csv')\n",
    "ins.head(5) # displaying top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset, that has column values with special charecters like in the case of report_available, which needs to be handled and also check for duplicate values that hold no meaning and are redudant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 35)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we check the size of dataset that we are dealing with.\n",
    "ins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw CSV that we are dealing here has about 35 columns and 299 Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID                     0\n",
       "age                            0\n",
       "age_category                   0\n",
       "sex                            0\n",
       "bmi                            0\n",
       "SeniorCitizen                  0\n",
       "children                       0\n",
       "smoker                         0\n",
       "NUMBER                         0\n",
       "STREET                         0\n",
       "state                          3\n",
       "region                         0\n",
       "self_employed                 11\n",
       "insured_occupation             0\n",
       "family_history                 0\n",
       "PaymentMethod                  0\n",
       "Enrollment charges             0\n",
       "Average Monthly Tax Credit     0\n",
       "Average Yearly Tax Credit      0\n",
       "Medicaid Enrollment            0\n",
       "Medicaid Enrollment ID        18\n",
       "Medicare Enrollment ID         0\n",
       "Metal Level                    0\n",
       "Issuer Name                    0\n",
       "HIOS Issuer ID                 0\n",
       "Plan ID                        0\n",
       "policy_bind_date               0\n",
       "Plan Marketing Name            0\n",
       "Plan Type                      0\n",
       "policy_bind_date.1             0\n",
       "months_as_customer             0\n",
       "umbrella_limit                 0\n",
       "total_claim_amount             0\n",
       "report_available               0\n",
       "claim_date                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For Audit purpose let's check if our dataset holds any null values.\n",
    "ins.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the data into Database, we need to handle those null fields values, in real-world scenario we can either choose to replace them or delete them depending upon the business case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To increase the quality of the data, we will be dropping the records having any null values\n",
    "ins = ins.dropna()\n",
    "ins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insurance Database\n",
    "\n",
    "Now let us try to view the our Database Schema to understand, what are the tables we shall be building in to form our Insurance Database. We use the Entity-Relationship(ER) diagram to visualize our database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"Copy ofInsurance.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames following the same schema of the corresponding tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we shall create dataframes\n",
    "policy = pd.DataFrame(columns = ['Plan_ID','Medicaid_Enrollment','Medicaid_Enrollment_ID','Medicare_Enrollment_ID',\n",
    "                                 'Plan_Marketing_Name','Plan_Type','Provider_ID'])\n",
    "insu_provider = pd.DataFrame(columns = ['Provider_ID','Issuer_Name','HIOS_Issuer_ID','Metal_Level'])\n",
    "claims = pd.DataFrame(columns = ['Claim ID','Plan_ID','Umbrella_Limit','Total_Claim_Amount','Report_Available'])\n",
    "customer_address = pd.DataFrame(columns = ['Address_ID','Number','Street','State','Region','customerID'])\n",
    "payment = pd.DataFrame(columns = ['Payment_ID','Plan_ID','Payment_Method','Enrollment_Charges',\n",
    "                                  'Average_Monthly_Tax_Credit','Average_Yearly_Tax_Credit','customerID'])\n",
    "#https://stackoverflow.com/questions/34682828/extracting-specific-selected-columns-to-new-dataframe-as-a-cop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 NF Normalization:\n",
    "\n",
    "Now we shall try to achive 1NF from on the Game Inventory by adding Primary Key. The same shall be done for all the tables to achieve the 1NF across the tables in the database that we are building.\n",
    "\n",
    "# Customer Table:\n",
    "\n",
    "Filtering the ins dataframe for customer details using filter function in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>children</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>family_history</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age_category</th>\n",
       "      <th>Plan_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>8091-TTVAX</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>176</td>\n",
       "      <td>Major</td>\n",
       "      <td>60224GA0020005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0280-XJGEX</td>\n",
       "      <td>56</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>Major</td>\n",
       "      <td>33653ME0050002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5129-JLPIS</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>169</td>\n",
       "      <td>Major</td>\n",
       "      <td>29276OH0920418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3655-SNQYZ</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>89</td>\n",
       "      <td>Minor</td>\n",
       "      <td>20129IL0330020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>8191-XWSZG</td>\n",
       "      <td>52</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>85</td>\n",
       "      <td>Major</td>\n",
       "      <td>37833WI0380028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customerID  age     sex  children  SeniorCitizen family_history  \\\n",
       "12  8091-TTVAX   23    male         0              0            Yes   \n",
       "13  0280-XJGEX   56  female         0              0             No   \n",
       "14  5129-JLPIS   27    male         0              0             No   \n",
       "15  3655-SNQYZ   19    male         1              0             No   \n",
       "16  8191-XWSZG   52  female         1              0            Yes   \n",
       "\n",
       "    months_as_customer age_category         Plan_ID  \n",
       "12                 176        Major  60224GA0020005  \n",
       "13                  79        Major  33653ME0050002  \n",
       "14                 169        Major  29276OH0920418  \n",
       "15                  89        Minor  20129IL0330020  \n",
       "16                  85        Major  37833WI0380028  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer =  pd.DataFrame(columns = ['customerID','age','sex','children','SeniorCitizen','family_history','months_as_customer','age_category','Plan ID'])\n",
    "customer = ins.filter(['customerID','age','sex','children','SeniorCitizen','family_history','months_as_customer','age_category','Plan ID '],axis =1)\n",
    "# Renaming the 'Plan ID ' column to 'Plan_ID'\n",
    "customer = customer.rename(columns={'Plan ID ': 'Plan_ID'})\n",
    "customer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plan_ID</th>\n",
       "      <th>Medicaid_Enrollment</th>\n",
       "      <th>Medicaid_Enrollment_ID</th>\n",
       "      <th>Medicare_Enrollment_ID</th>\n",
       "      <th>Plan_Marketing_Name</th>\n",
       "      <th>Plan_Type</th>\n",
       "      <th>Provider_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60224GA0020005</td>\n",
       "      <td>False</td>\n",
       "      <td>9935517.0</td>\n",
       "      <td>294284</td>\n",
       "      <td>CareSource Marketplace Low Deductible Silver D...</td>\n",
       "      <td>HMO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33653ME0050002</td>\n",
       "      <td>True</td>\n",
       "      <td>5727510.0</td>\n",
       "      <td>2118300</td>\n",
       "      <td>Community Advance PPO</td>\n",
       "      <td>PPO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29276OH0920418</td>\n",
       "      <td>True</td>\n",
       "      <td>1220788.0</td>\n",
       "      <td>1181014</td>\n",
       "      <td>Anthem Silver Pathway X HMO 10 for HSA</td>\n",
       "      <td>HMO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20129IL0330020</td>\n",
       "      <td>True</td>\n",
       "      <td>2748165.0</td>\n",
       "      <td>587780</td>\n",
       "      <td>HMO 8150 Elite Catastrophic</td>\n",
       "      <td>HMO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>37833WI0380028</td>\n",
       "      <td>False</td>\n",
       "      <td>4123280.0</td>\n",
       "      <td>499753</td>\n",
       "      <td>Quartz One Silver I302 with Dental</td>\n",
       "      <td>HMO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Plan_ID  Medicaid_Enrollment  Medicaid_Enrollment_ID  \\\n",
       "0  60224GA0020005                False               9935517.0   \n",
       "1  33653ME0050002                 True               5727510.0   \n",
       "2  29276OH0920418                 True               1220788.0   \n",
       "3  20129IL0330020                 True               2748165.0   \n",
       "4  37833WI0380028                False               4123280.0   \n",
       "\n",
       "   Medicare_Enrollment_ID                                Plan_Marketing_Name  \\\n",
       "0                  294284  CareSource Marketplace Low Deductible Silver D...   \n",
       "1                 2118300                              Community Advance PPO   \n",
       "2                 1181014             Anthem Silver Pathway X HMO 10 for HSA   \n",
       "3                  587780                        HMO 8150 Elite Catastrophic   \n",
       "4                  499753                 Quartz One Silver I302 with Dental   \n",
       "\n",
       "  Plan_Type Provider_ID  \n",
       "0       HMO         NaN  \n",
       "1       PPO         NaN  \n",
       "2       HMO         NaN  \n",
       "3       HMO         NaN  \n",
       "4       HMO         NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy['Plan_ID'] = ins['Plan ID '].unique()\n",
    "# since the dataset that we handle here has already a column Plan_ID which we shall make as our Primary Key, by ensuring that each record in that column is unique\n",
    "med_enro = []\n",
    "med_enro_id = []\n",
    "med_care_id = []\n",
    "plan_mark_name = []\n",
    "plan_type = []\n",
    "# Now that we have the table schema defined, we shall pull the records from our ins Dataframe into appropriate columns\n",
    "for i in policy['Plan_ID']:\n",
    "    value = ins.loc[(ins['Plan ID '] == i),'Medicaid Enrollment'].tolist()[0]\n",
    "    value1 = ins.loc[(ins['Plan ID '] == i),'Medicaid Enrollment ID'].tolist()[0]\n",
    "    value2 = ins.loc[(ins['Plan ID '] == i),'Medicare Enrollment ID'].tolist()[0]\n",
    "    value3 = ins.loc[(ins['Plan ID '] == i),'Plan Marketing Name'].tolist()[0]\n",
    "    value4 = ins.loc[(ins['Plan ID '] == i),'Plan Type'].tolist()[0]\n",
    "    med_enro.append(value)\n",
    "    med_enro_id.append(value1)\n",
    "    med_care_id.append(value2)\n",
    "    plan_mark_name.append(value3)\n",
    "    plan_type.append(value4)\n",
    "policy['Medicaid_Enrollment'] = med_enro\n",
    "policy['Medicaid_Enrollment_ID'] = med_enro_id\n",
    "policy['Medicare_Enrollment_ID'] = med_care_id \n",
    "policy['Plan_Marketing_Name'] = plan_mark_name\n",
    "policy['Plan_Type'] = plan_type\n",
    "# Displaying the top 5 records of Policy table\n",
    "policy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: That for the policy table we have column Provider_ID which has value NA loaded now. This is done to have an entity relationship between the Policy Table and the Provider Table. The kind of relation between the two entites is maintained as defined in the ER Diagram shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provider Table:\n",
    "\n",
    "Creating Provider table schema and loading the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider_ID</th>\n",
       "      <th>Issuer_Name</th>\n",
       "      <th>HIOS_Issuer_ID</th>\n",
       "      <th>Metal_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>CareSource Georgia Co.</td>\n",
       "      <td>60224</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>Community Health Options</td>\n",
       "      <td>33653</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>203</td>\n",
       "      <td>Anthem Blue Cross and Blue Shield</td>\n",
       "      <td>29276</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>204</td>\n",
       "      <td>Health Alliance Medical Plans, Inc.</td>\n",
       "      <td>20129</td>\n",
       "      <td>Catastrophic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>205</td>\n",
       "      <td>Quartz</td>\n",
       "      <td>37833</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider_ID                          Issuer_Name  HIOS_Issuer_ID  \\\n",
       "0          201               CareSource Georgia Co.           60224   \n",
       "1          202             Community Health Options           33653   \n",
       "2          203    Anthem Blue Cross and Blue Shield           29276   \n",
       "3          204  Health Alliance Medical Plans, Inc.           20129   \n",
       "4          205                               Quartz           37833   \n",
       "\n",
       "    Metal_Level  \n",
       "0        Silver  \n",
       "1        Silver  \n",
       "2        Silver  \n",
       "3  Catastrophic  \n",
       "4        Silver  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insu_provider['Issuer_Name'] = ins['Issuer Name'].unique()\n",
    "# here also we have a column Prov_Id from our raw csv, which we shall consider as primary key to our Provider Table, to ensure that the column loads with unique values we apply the unique function to the list\n",
    "hios_temp = []\n",
    "metal_temp = []\n",
    "prov_id = []\n",
    "j = 201\n",
    "\n",
    "# Now we shall load the data from our ins dataframe into the appropriate columns\n",
    "for i in insu_provider['Issuer_Name']:\n",
    "    value = ins.loc[(ins['Issuer Name'] == i),'HIOS Issuer ID'].tolist()[0]\n",
    "    value1 = ins.loc[(ins['Issuer Name'] == i),'Metal Level'].tolist()[0]\n",
    "    hios_temp.append(value)\n",
    "    metal_temp.append(value1)\n",
    "    prov_id.append(j)\n",
    "    j += 1\n",
    "insu_provider['HIOS_Issuer_ID'] = hios_temp\n",
    "insu_provider['Metal_Level'] = metal_temp\n",
    "insu_provider['Provider_ID'] = prov_id\n",
    "#displaying top 5 records\n",
    "insu_provider.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claim Table:\n",
    "\n",
    "Creating Claim table schema and loading the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim ID</th>\n",
       "      <th>Plan_ID</th>\n",
       "      <th>Umbrella_Limit</th>\n",
       "      <th>Total_Claim_Amount</th>\n",
       "      <th>Report_Available</th>\n",
       "      <th>Claim-ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60224GA0020005</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>11310</td>\n",
       "      <td>?</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33653ME0050002</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>108710</td>\n",
       "      <td>?</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29276OH0920418</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>2690</td>\n",
       "      <td>YES</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20129IL0330020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>NO</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37833WI0380028</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>71240</td>\n",
       "      <td>?</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Claim ID         Plan_ID  Umbrella_Limit  Total_Claim_Amount  \\\n",
       "0      NaN  60224GA0020005       1000000.0               11310   \n",
       "1      NaN  33653ME0050002       2000000.0              108710   \n",
       "2      NaN  29276OH0920418       2000000.0                2690   \n",
       "3      NaN  20129IL0330020             0.0                1500   \n",
       "4      NaN  37833WI0380028       1000000.0               71240   \n",
       "\n",
       "  Report_Available  Claim-ID  \n",
       "0                ?       601  \n",
       "1                ?       602  \n",
       "2              YES       603  \n",
       "3               NO       604  \n",
       "4                ?       605  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umb_temp = []\n",
    "j = 601# here to generate a ClaimId we shall consider the generating some random number starting from 601\n",
    "tot_claim_temp = []\n",
    "rep_avail = []\n",
    "claim_id = []\n",
    "claims['Plan_ID'] = ins['Plan ID '].unique()\n",
    "\n",
    "#once the schema for the Claim table is ready we shall try to load the ins data into the claim table\n",
    "for i in claims['Plan_ID']:\n",
    "    value1 = ins.loc[(ins['Plan ID '] == i),'umbrella_limit'].tolist()[0]\n",
    "    value2 = ins.loc[(ins['Plan ID '] == i),'total_claim_amount'].tolist()[0]\n",
    "    value3 = ins.loc[(ins['Plan ID '] == i),'report_available'].tolist()[0]\n",
    "    umb_temp.append(value1)\n",
    "    tot_claim_temp.append(value2)\n",
    "    rep_avail.append(value3)\n",
    "    claim_id.append(j)\n",
    "    j += 1\n",
    "claims['Claim_ID'] = claim_id\n",
    "claims['Umbrella_Limit'] = umb_temp\n",
    "claims['Total_Claim_Amount'] = tot_claim_temp\n",
    "claims['Report_Available'] = rep_avail\n",
    "#displaying top 5 rows\n",
    "claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>children</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>family_history</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age_category</th>\n",
       "      <th>Plan_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>8091-TTVAX</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>176</td>\n",
       "      <td>Major</td>\n",
       "      <td>60224GA0020005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0280-XJGEX</td>\n",
       "      <td>56</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>Major</td>\n",
       "      <td>33653ME0050002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5129-JLPIS</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>169</td>\n",
       "      <td>Major</td>\n",
       "      <td>29276OH0920418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3655-SNQYZ</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>89</td>\n",
       "      <td>Minor</td>\n",
       "      <td>20129IL0330020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>8191-XWSZG</td>\n",
       "      <td>52</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>85</td>\n",
       "      <td>Major</td>\n",
       "      <td>37833WI0380028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customerID  age     sex  children  SeniorCitizen family_history  \\\n",
       "12  8091-TTVAX   23    male         0              0            Yes   \n",
       "13  0280-XJGEX   56  female         0              0             No   \n",
       "14  5129-JLPIS   27    male         0              0             No   \n",
       "15  3655-SNQYZ   19    male         1              0             No   \n",
       "16  8191-XWSZG   52  female         1              0            Yes   \n",
       "\n",
       "    months_as_customer age_category         Plan_ID  \n",
       "12                 176        Major  60224GA0020005  \n",
       "13                  79        Major  33653ME0050002  \n",
       "14                 169        Major  29276OH0920418  \n",
       "15                  89        Minor  20129IL0330020  \n",
       "16                  85        Major  37833WI0380028  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer_Address Table:\n",
    "\n",
    "Creating Customer Address table schema and loading the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address_ID</th>\n",
       "      <th>Number</th>\n",
       "      <th>Street</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "      <th>customerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>901</td>\n",
       "      <td>26</td>\n",
       "      <td>Magnolia Ln</td>\n",
       "      <td>NY</td>\n",
       "      <td>southwest</td>\n",
       "      <td>8091-TTVAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>902</td>\n",
       "      <td>61</td>\n",
       "      <td>Highview Ter</td>\n",
       "      <td>NC</td>\n",
       "      <td>southeast</td>\n",
       "      <td>0280-XJGEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>903</td>\n",
       "      <td>878</td>\n",
       "      <td>Chamberlain Hwy</td>\n",
       "      <td>MA</td>\n",
       "      <td>southeast</td>\n",
       "      <td>5129-JLPIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>904</td>\n",
       "      <td>782</td>\n",
       "      <td>Kensington Rd</td>\n",
       "      <td>IA</td>\n",
       "      <td>southwest</td>\n",
       "      <td>3655-SNQYZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>905</td>\n",
       "      <td>34</td>\n",
       "      <td>Magnolia Ln</td>\n",
       "      <td>CA</td>\n",
       "      <td>northeast</td>\n",
       "      <td>8191-XWSZG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Address_ID  Number           Street State     Region  customerID\n",
       "12         901      26      Magnolia Ln    NY  southwest  8091-TTVAX\n",
       "13         902      61     Highview Ter    NC  southeast  0280-XJGEX\n",
       "14         903     878  Chamberlain Hwy    MA  southeast  5129-JLPIS\n",
       "15         904     782    Kensington Rd    IA  southwest  3655-SNQYZ\n",
       "16         905      34      Magnolia Ln    CA  northeast  8191-XWSZG"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_address['customerID'] = ins.customerID\n",
    "customer_address['Number'] = ins['NUMBER']\n",
    "customer_address['Street'] = ins.STREET\n",
    "customer_address['State'] = ins.state\n",
    "customer_address['Region'] = ins.region\n",
    "j = 901\n",
    "address_id = []\n",
    "for i in customer_address['Number']:\n",
    "    address_id.append(j)\n",
    "    j += 1\n",
    "customer_address.Address_ID = address_id\n",
    "#displaying the top 5 rows\n",
    "customer_address.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Payment Table:\n",
    "\n",
    "Creating Payment table schema and loading the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Payment_ID</th>\n",
       "      <th>Plan_ID</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Enrollment_Charges</th>\n",
       "      <th>Average_Monthly_Tax_Credit</th>\n",
       "      <th>Average_Yearly_Tax_Credit</th>\n",
       "      <th>customerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>554</td>\n",
       "      <td>392C445WQ5267</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>3906.1270</td>\n",
       "      <td>$293</td>\n",
       "      <td>$3516</td>\n",
       "      <td>1563-IWQEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>555</td>\n",
       "      <td>701F130FY9197</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>1704.5681</td>\n",
       "      <td>$146</td>\n",
       "      <td>$1752</td>\n",
       "      <td>8203-XJZRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>556</td>\n",
       "      <td>748D434TK3215</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>16297.8460</td>\n",
       "      <td>$377</td>\n",
       "      <td>$4524</td>\n",
       "      <td>6556-DBKZF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>557</td>\n",
       "      <td>864Y799RR6253</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>21978.6769</td>\n",
       "      <td>$215</td>\n",
       "      <td>$2580</td>\n",
       "      <td>6851-WEFYX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>558</td>\n",
       "      <td>100W188OU7332</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>38746.3551</td>\n",
       "      <td>$236</td>\n",
       "      <td>$2832</td>\n",
       "      <td>2985-JUUBZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Payment_ID        Plan_ID    Payment_Method  Enrollment_Charges  \\\n",
       "253         554  392C445WQ5267      Mailed check           3906.1270   \n",
       "254         555  701F130FY9197      Mailed check           1704.5681   \n",
       "255         556  748D434TK3215  Electronic check          16297.8460   \n",
       "256         557  864Y799RR6253  Electronic check          21978.6769   \n",
       "257         558  100W188OU7332  Electronic check          38746.3551   \n",
       "\n",
       "    Average_Monthly_Tax_Credit Average_Yearly_Tax_Credit  customerID  \n",
       "253                       $293                     $3516  1563-IWQEX  \n",
       "254                       $146                     $1752  8203-XJZRC  \n",
       "255                       $377                     $4524  6556-DBKZF  \n",
       "256                       $215                     $2580  6851-WEFYX  \n",
       "257                       $236                     $2832  2985-JUUBZ  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment['Plan_ID'] = ins['Plan ID '].unique()\n",
    "pay_method = []\n",
    "enro_charges = []\n",
    "av_month_tax = []\n",
    "av_year_tax = []\n",
    "cust_id = []\n",
    "payment_id = []\n",
    "j = 301#here again we try to generate a random number for the PaymentId column starting from 301\n",
    "for i in payment['Plan_ID']:\n",
    "    value1 = ins.loc[(ins['Plan ID ']==i),'PaymentMethod'].tolist()[0]\n",
    "    value2 = ins.loc[(ins['Plan ID ']==i),'Enrollment charges'].tolist()[0]\n",
    "    value3 = ins.loc[(ins['Plan ID ']==i), 'Average Monthly Tax Credit'].tolist()[0]\n",
    "    value4 = ins.loc[(ins['Plan ID ']==i), 'Average Yearly Tax Credit'].tolist()[0]\n",
    "    value5 = ins.loc[(ins['Plan ID ']==i), 'customerID'].tolist()[0]\n",
    "    pay_method.append(value1)\n",
    "    enro_charges.append(value2)\n",
    "    av_month_tax.append(value3)\n",
    "    av_year_tax.append(value4)\n",
    "    cust_id.append(value5)\n",
    "    payment_id.append(j)\n",
    "    j += 1\n",
    "# we pull each field value of a row and append intp the corresponding list \n",
    "payment['Payment_Method'] = pay_method\n",
    "payment['Enrollment_Charges'] = enro_charges\n",
    "payment['Average_Monthly_Tax_Credit'] = av_month_tax\n",
    "payment['Average_Yearly_Tax_Credit'] = av_year_tax\n",
    "payment['customerID'] = cust_id\n",
    "payment['Payment_ID'] = payment_id\n",
    "#displaying the top 5 rows\n",
    "payment.head()\n",
    "payment.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Normalization:\n",
    "\n",
    "In our Payments table we have a column Average_Yearly_Tax_Credit, which is calculated from the Average_Monthly_Tax_Credit * 12\n",
    "To achieve 2NF form, we should not have any calcuated columns. Hence, we remove the Average_Yearly_Tax_Credit from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Payment_ID</th>\n",
       "      <th>Plan_ID</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Enrollment_Charges</th>\n",
       "      <th>Average_Monthly_Tax_Credit</th>\n",
       "      <th>customerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>60224GA0020005</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>1826.84</td>\n",
       "      <td>$265</td>\n",
       "      <td>8091-TTVAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>33653ME0050002</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>11090.72</td>\n",
       "      <td>$237</td>\n",
       "      <td>0280-XJGEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>29276OH0920418</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>39611.76</td>\n",
       "      <td>$259</td>\n",
       "      <td>5129-JLPIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>304</td>\n",
       "      <td>20129IL0330020</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>1837.24</td>\n",
       "      <td>$307</td>\n",
       "      <td>3655-SNQYZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>305</td>\n",
       "      <td>37833WI0380028</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>10797.34</td>\n",
       "      <td>$247</td>\n",
       "      <td>8191-XWSZG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Payment_ID         Plan_ID             Payment_Method  Enrollment_Charges  \\\n",
       "0         301  60224GA0020005    Credit card (automatic)             1826.84   \n",
       "1         302  33653ME0050002  Bank transfer (automatic)            11090.72   \n",
       "2         303  29276OH0920418           Electronic check            39611.76   \n",
       "3         304  20129IL0330020    Credit card (automatic)             1837.24   \n",
       "4         305  37833WI0380028               Mailed check            10797.34   \n",
       "\n",
       "  Average_Monthly_Tax_Credit  customerID  \n",
       "0                      $265   8091-TTVAX  \n",
       "1                      $237   0280-XJGEX  \n",
       "2                      $259   5129-JLPIS  \n",
       "3                      $307   3655-SNQYZ  \n",
       "4                      $247   8191-XWSZG  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment = payment.drop(columns=['Average_Yearly_Tax_Credit'])\n",
    "payment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>children</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>family_history</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age_category</th>\n",
       "      <th>Plan_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>3580-REOAC</td>\n",
       "      <td>52</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>414</td>\n",
       "      <td>Major</td>\n",
       "      <td>160P883IN8477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>7534-BFESC</td>\n",
       "      <td>28</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>316</td>\n",
       "      <td>Major</td>\n",
       "      <td>710U610AC4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>3727-OWVYD</td>\n",
       "      <td>29</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>105</td>\n",
       "      <td>Major</td>\n",
       "      <td>969N739XY3979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>2294-SALNE</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>93</td>\n",
       "      <td>Major</td>\n",
       "      <td>205K482FE6220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>4847-TAJYI</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>103</td>\n",
       "      <td>Major</td>\n",
       "      <td>364S829VL9586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>1563-IWQEX</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>141</td>\n",
       "      <td>Major</td>\n",
       "      <td>392C445WQ5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>8203-XJZRC</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>256</td>\n",
       "      <td>Minor</td>\n",
       "      <td>701F130FY9197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>6556-DBKZF</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>177</td>\n",
       "      <td>Minor</td>\n",
       "      <td>748D434TK3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>6851-WEFYX</td>\n",
       "      <td>47</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>245</td>\n",
       "      <td>Major</td>\n",
       "      <td>864Y799RR6253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>2985-JUUBZ</td>\n",
       "      <td>31</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>186</td>\n",
       "      <td>Major</td>\n",
       "      <td>100W188OU7332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     customerID  age     sex  children  SeniorCitizen family_history  \\\n",
       "289  3580-REOAC   52    male         3              0             No   \n",
       "290  7534-BFESC   28  female         0              1             No   \n",
       "291  3727-OWVYD   29    male         1              0             No   \n",
       "292  2294-SALNE   25    male         2              0            Yes   \n",
       "293  4847-TAJYI   22  female         0              1            Yes   \n",
       "294  1563-IWQEX   25    male         3              0             No   \n",
       "295  8203-XJZRC   18    male         0              0             No   \n",
       "296  6556-DBKZF   19    male         0              0            Yes   \n",
       "297  6851-WEFYX   47    male         1              1            Yes   \n",
       "298  2985-JUUBZ   31    male         3              0            Yes   \n",
       "\n",
       "     months_as_customer age_category        Plan_ID  \n",
       "289                 414        Major  160P883IN8477  \n",
       "290                 316        Major  710U610AC4760  \n",
       "291                 105        Major  969N739XY3979  \n",
       "292                  93        Major  205K482FE6220  \n",
       "293                 103        Major  364S829VL9586  \n",
       "294                 141        Major  392C445WQ5267  \n",
       "295                 256        Minor  701F130FY9197  \n",
       "296                 177        Minor  748D434TK3215  \n",
       "297                 245        Major  864Y799RR6253  \n",
       "298                 186        Major  100W188OU7332  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our Customer Table we have a column age_category, which assigns if each customer is Minor or Major. This field is calculated based upon the age value, if a customer is less than 19, he/she is considered as minor else assigned value major. To achieve 2NF we shouldn't have any calculated field, since age_category is a calculated column we choose to drop the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>children</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>family_history</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>Plan_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>8091-TTVAX</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>176</td>\n",
       "      <td>60224GA0020005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0280-XJGEX</td>\n",
       "      <td>56</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>33653ME0050002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5129-JLPIS</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>169</td>\n",
       "      <td>29276OH0920418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3655-SNQYZ</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>89</td>\n",
       "      <td>20129IL0330020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>8191-XWSZG</td>\n",
       "      <td>52</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>85</td>\n",
       "      <td>37833WI0380028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customerID  age     sex  children  SeniorCitizen family_history  \\\n",
       "12  8091-TTVAX   23    male         0              0            Yes   \n",
       "13  0280-XJGEX   56  female         0              0             No   \n",
       "14  5129-JLPIS   27    male         0              0             No   \n",
       "15  3655-SNQYZ   19    male         1              0             No   \n",
       "16  8191-XWSZG   52  female         1              0            Yes   \n",
       "\n",
       "    months_as_customer         Plan_ID  \n",
       "12                 176  60224GA0020005  \n",
       "13                  79  33653ME0050002  \n",
       "14                 169  29276OH0920418  \n",
       "15                  89  20129IL0330020  \n",
       "16                  85  37833WI0380028  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer = customer.drop(columns=['age_category'])\n",
    "customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Normalization:\n",
    "\n",
    "\n",
    "To achieve the 3NF each column in the table should have direct relation to the PK. We have ID columns of other tables which are kept to establish a relationship to another table, this is called the Primarykey-Foreignkey relation. Here in our project, we show such relationship using the Policy and Provider table. An Insurance provider shall have many policies under its plan, so each Policy in the Policy table will be linked to an Insurance provider in the Provider table. \n",
    "This is what achieved from the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plan_ID</th>\n",
       "      <th>Medicaid_Enrollment</th>\n",
       "      <th>Medicaid_Enrollment_ID</th>\n",
       "      <th>Medicare_Enrollment_ID</th>\n",
       "      <th>Plan_Marketing_Name</th>\n",
       "      <th>Plan_Type</th>\n",
       "      <th>Provider_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>160P883IN8477</td>\n",
       "      <td>True</td>\n",
       "      <td>189429.0</td>\n",
       "      <td>7235717</td>\n",
       "      <td>my Blue Access EPO Silver 3950 HSA</td>\n",
       "      <td>EPO</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>710U610AC4760</td>\n",
       "      <td>True</td>\n",
       "      <td>918868.0</td>\n",
       "      <td>2561709</td>\n",
       "      <td>BlueOptions Platinum 1424</td>\n",
       "      <td>EPO</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>969N739XY3979</td>\n",
       "      <td>False</td>\n",
       "      <td>788544.0</td>\n",
       "      <td>8130629</td>\n",
       "      <td>Anthem Bronze Pathway X HMO 5200</td>\n",
       "      <td>HMO</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>205K482FE6220</td>\n",
       "      <td>True</td>\n",
       "      <td>5146113.0</td>\n",
       "      <td>4009357</td>\n",
       "      <td>my Blue Access WV Major Events EPO 8150 - 3 Fr...</td>\n",
       "      <td>EPO</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>364S829VL9586</td>\n",
       "      <td>True</td>\n",
       "      <td>6357489.0</td>\n",
       "      <td>4381867</td>\n",
       "      <td>my Blue Access WV EPO Gold 800 - 2 Free PCP Vi...</td>\n",
       "      <td>EPO</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>392C445WQ5267</td>\n",
       "      <td>True</td>\n",
       "      <td>9239334.0</td>\n",
       "      <td>5357375</td>\n",
       "      <td>CareSource Marketplace Gold Dental, Vision, &amp; ...</td>\n",
       "      <td>HMO</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>701F130FY9197</td>\n",
       "      <td>False</td>\n",
       "      <td>180874.0</td>\n",
       "      <td>1873043</td>\n",
       "      <td>Ambetter Secure Care 5 (2020) + Vision + Adult...</td>\n",
       "      <td>EPO</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>748D434TK3215</td>\n",
       "      <td>False</td>\n",
       "      <td>1766047.0</td>\n",
       "      <td>6636223</td>\n",
       "      <td>my Blue Access WV EPO Gold 800 - 2 Free PCP Vi...</td>\n",
       "      <td>EPO</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>864Y799RR6253</td>\n",
       "      <td>False</td>\n",
       "      <td>693869.0</td>\n",
       "      <td>793561</td>\n",
       "      <td>IND Bronze HMO  7500</td>\n",
       "      <td>HMO</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>100W188OU7332</td>\n",
       "      <td>False</td>\n",
       "      <td>2072282.0</td>\n",
       "      <td>5401092</td>\n",
       "      <td>CareSource Marketplace Low Deductible Silver D...</td>\n",
       "      <td>HMO</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Plan_ID  Medicaid_Enrollment  Medicaid_Enrollment_ID  \\\n",
       "248  160P883IN8477                 True                189429.0   \n",
       "249  710U610AC4760                 True                918868.0   \n",
       "250  969N739XY3979                False                788544.0   \n",
       "251  205K482FE6220                 True               5146113.0   \n",
       "252  364S829VL9586                 True               6357489.0   \n",
       "253  392C445WQ5267                 True               9239334.0   \n",
       "254  701F130FY9197                False                180874.0   \n",
       "255  748D434TK3215                False               1766047.0   \n",
       "256  864Y799RR6253                False                693869.0   \n",
       "257  100W188OU7332                False               2072282.0   \n",
       "\n",
       "     Medicare_Enrollment_ID  \\\n",
       "248                 7235717   \n",
       "249                 2561709   \n",
       "250                 8130629   \n",
       "251                 4009357   \n",
       "252                 4381867   \n",
       "253                 5357375   \n",
       "254                 1873043   \n",
       "255                 6636223   \n",
       "256                  793561   \n",
       "257                 5401092   \n",
       "\n",
       "                                   Plan_Marketing_Name Plan_Type  Provider_ID  \n",
       "248                 my Blue Access EPO Silver 3950 HSA       EPO          220  \n",
       "249                          BlueOptions Platinum 1424       EPO          251  \n",
       "250                   Anthem Bronze Pathway X HMO 5200       HMO          213  \n",
       "251  my Blue Access WV Major Events EPO 8150 - 3 Fr...       EPO          254  \n",
       "252  my Blue Access WV EPO Gold 800 - 2 Free PCP Vi...       EPO          213  \n",
       "253  CareSource Marketplace Gold Dental, Vision, & ...       HMO          220  \n",
       "254  Ambetter Secure Care 5 (2020) + Vision + Adult...       EPO          240  \n",
       "255  my Blue Access WV EPO Gold 800 - 2 Free PCP Vi...       EPO          265  \n",
       "256                               IND Bronze HMO  7500       HMO          206  \n",
       "257  CareSource Marketplace Low Deductible Silver D...       HMO          203  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adding the generated provider id to corresponding columns in policy\n",
    "prov_id_temp =[]\n",
    "#here  we first pull the Provider Ids from the Provider table and try to load into the empty list\n",
    "for i in ins['Issuer Name']:\n",
    "    values = insu_provider.loc[insu_provider['Issuer_Name'] == i,'Provider_ID'].tolist()[0]\n",
    "    prov_id_temp.append(values)\n",
    "ins['Provider ID'] = prov_id_temp\n",
    "# now the pulled provider id details are assigned to each rows of the Policy Table to achieve the 3NF \n",
    "prov_id_new = []\n",
    "for i in policy['Plan_ID']:\n",
    "    values = ins.loc[(ins['Plan ID '] == i),'Provider ID'].tolist()[0]\n",
    "    prov_id_new.append(values)\n",
    "policy['Provider_ID'] = prov_id_new\n",
    "#\n",
    "policy.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media Scrapping\n",
    "\n",
    "To use real-time data in our project, we have scrapped the Twitter's Tweets using the Twitter API provided by the service provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "#these keys are all shared by the twitter api to scrap the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to AWS RDS Database\n",
    "\n",
    "Since the primary goal of the project it to have a database setup in virtual cloud platform, we now connect to the AWS RDS database that holds our Insurance Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = 'dmdd.cep3r0xw222loxj.us-east-21.rds.amazonaws.com'\n",
    "USER = 'admini'\n",
    "PASSWD = 'superman******12345'\n",
    "DATABASE = 'aws_insurance'\n",
    "# all the connection details have been masked for security purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to Twitter to scrap the Tweets and Twitter User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now shall try to pull the data for our social media, by scrapping in tweets from Twitter \n",
    "def store_data(created_at, text, screen_name, tweet_id,location,followers_count):\n",
    "    db=MySQLdb.connect(host=HOST, user=USER, passwd=PASSWD, db=DATABASE, charset=\"utf8\")\n",
    "    cursor = db.cursor()\n",
    "    insert_query = \"INSERT INTO twitter (tweet_id, screen_name,created_at, text, location,follower_count) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "    cursor.execute(insert_query, (tweet_id, screen_name, created_at, text, location,followers_count))\n",
    "    db.commit()\n",
    "    cursor.close()\n",
    "    db.close()\n",
    "    return\n",
    "class StreamListener(tweepy.StreamListener):    \n",
    "    #This is a class provided by tweepy to access the Twitter Streaming API. \n",
    "\n",
    "    def on_connect(self):\n",
    "        # Called initially to connect to the Streaming API\n",
    "        print(\"You are now connected to the streaming API.\")\n",
    " \n",
    "    def on_error(self, status_code):\n",
    "        # On error - if an error occurs, display the error / status code\n",
    "        print('An Error has occured: ' + repr(status_code))\n",
    "        return False\n",
    " \n",
    "    def on_data(self, data):\n",
    "        #This is the meat of the script...it connects to your database and stores the tweet\n",
    "        try:\n",
    "           # Decode the JSON from Twitter\n",
    "            datajson = json.loads(data)\n",
    "            \n",
    "            #grab the wanted data from the Tweet\n",
    "            text = datajson['text']\n",
    "            screen_name = datajson['user']['screen_name']\n",
    "            tweet_id = datajson['id']\n",
    "            created_at = parser.parse(datajson['created_at'])\n",
    "            #hashtag = re.findall(r\"#(\\w+)\",datajson['text'])\n",
    "            location = datajson['user']['location']\n",
    "            followers_count = datajson['user']['followers_count']\n",
    "\n",
    "            #print out a message to the screen that we have collected a tweet\n",
    "            print(\"Tweet collected at \" + str(created_at))\n",
    "            \n",
    "            #insert the data into the MySQL database\n",
    "            store_data(created_at, text, screen_name, tweet_id,location,followers_count)\n",
    "        \n",
    "        except Exception as e:\n",
    "           print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shall try creating a schema for the twitter table that we scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_mysql.connection open to 'dmdd.cep3r0xwloxj.us-east-2.rds.amazonaws.com' at 0000005F319DC988>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = MySQLdb.connect(host=HOST, user=USER, passwd=PASSWD, db=DATABASE, charset=\"utf8\")\n",
    "print (db)\n",
    "cursor = db.cursor()\n",
    "#Drop the twitter table\n",
    "#cursor.execute(\"drop table `twitter`\")\n",
    "\n",
    "# create a table called twitter\n",
    "cursor.execute(\"\"\"CREATE TABLE `twitter` (\n",
    "`id` int(11) NOT NULL AUTO_INCREMENT,\n",
    " `tweet_id` varchar(250) DEFAULT NULL,\n",
    " `screen_name` varchar(128) DEFAULT NULL,\n",
    " `created_at` timestamp NULL DEFAULT NULL,\n",
    " `text` text,\n",
    " `location` varchar(128) DEFAULT NULL,\n",
    " `follower_count` int(128) DEFAULT NULL,\n",
    " PRIMARY KEY (`id`)\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping Tweets that contains keywords:\n",
    "\n",
    "Here we scrape the tweet data from twitter that contains hastag like '#medicaid','#medicare','#usmedicalinsurance','#usinsurance' etc\n",
    "for our Tweets table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: ['#medicaid', '#medicare', '#usmedicalinsurance', '#usinsurance', 'medic aid', 'medicare', 'medicaid', 'medic care']\n",
      "You are now connected to the streaming API.\n",
      "Tweet collected at 2020-04-24 22:13:40+00:00\n",
      "Tweet collected at 2020-04-24 22:13:41+00:00\n",
      "Tweet collected at 2020-04-24 22:13:48+00:00\n",
      "Tweet collected at 2020-04-24 22:14:09+00:00\n",
      "Tweet collected at 2020-04-24 22:14:10+00:00\n",
      "Tweet collected at 2020-04-24 22:14:15+00:00\n",
      "Tweet collected at 2020-04-24 22:14:19+00:00\n",
      "Tweet collected at 2020-04-24 22:14:20+00:00\n",
      "Tweet collected at 2020-04-24 22:14:21+00:00\n",
      "Tweet collected at 2020-04-24 22:14:27+00:00\n",
      "Tweet collected at 2020-04-24 22:14:32+00:00\n",
      "Tweet collected at 2020-04-24 22:14:41+00:00\n",
      "Tweet collected at 2020-04-24 22:14:41+00:00\n",
      "Tweet collected at 2020-04-24 22:14:46+00:00\n",
      "Tweet collected at 2020-04-24 22:14:52+00:00\n",
      "Tweet collected at 2020-04-24 22:15:03+00:00\n",
      "Tweet collected at 2020-04-24 22:15:06+00:00\n",
      "Tweet collected at 2020-04-24 22:15:07+00:00\n",
      "Tweet collected at 2020-04-24 22:15:08+00:00\n",
      "Tweet collected at 2020-04-24 22:15:13+00:00\n",
      "Tweet collected at 2020-04-24 22:15:15+00:00\n",
      "Tweet collected at 2020-04-24 22:15:17+00:00\n",
      "Tweet collected at 2020-04-24 22:15:17+00:00\n",
      "Tweet collected at 2020-04-24 22:15:17+00:00\n",
      "Tweet collected at 2020-04-24 22:15:18+00:00\n",
      "Tweet collected at 2020-04-24 22:15:26+00:00\n",
      "Tweet collected at 2020-04-24 22:15:29+00:00\n",
      "Tweet collected at 2020-04-24 22:15:43+00:00\n",
      "Tweet collected at 2020-04-24 22:15:45+00:00\n",
      "Tweet collected at 2020-04-24 22:15:46+00:00\n",
      "Tweet collected at 2020-04-24 22:15:57+00:00\n",
      "Tweet collected at 2020-04-24 22:16:04+00:00\n",
      "Tweet collected at 2020-04-24 22:16:12+00:00\n",
      "Tweet collected at 2020-04-24 22:16:16+00:00\n",
      "Tweet collected at 2020-04-24 22:16:18+00:00\n",
      "Tweet collected at 2020-04-24 22:16:20+00:00\n",
      "Tweet collected at 2020-04-24 22:16:22+00:00\n",
      "Tweet collected at 2020-04-24 22:16:22+00:00\n",
      "Tweet collected at 2020-04-24 22:16:23+00:00\n",
      "Tweet collected at 2020-04-24 22:16:27+00:00\n",
      "Tweet collected at 2020-04-24 22:16:28+00:00\n",
      "Tweet collected at 2020-04-24 22:16:31+00:00\n",
      "Tweet collected at 2020-04-24 22:16:32+00:00\n",
      "Tweet collected at 2020-04-24 22:16:39+00:00\n",
      "Tweet collected at 2020-04-24 22:16:46+00:00\n",
      "Tweet collected at 2020-04-24 22:16:50+00:00\n",
      "Tweet collected at 2020-04-24 22:16:52+00:00\n",
      "Tweet collected at 2020-04-24 22:16:55+00:00\n",
      "Tweet collected at 2020-04-24 22:16:59+00:00\n",
      "Tweet collected at 2020-04-24 22:17:09+00:00\n",
      "Tweet collected at 2020-04-24 22:17:14+00:00\n",
      "Tweet collected at 2020-04-24 22:17:15+00:00\n",
      "Tweet collected at 2020-04-24 22:17:24+00:00\n",
      "Tweet collected at 2020-04-24 22:17:30+00:00\n",
      "Tweet collected at 2020-04-24 22:17:35+00:00\n",
      "Tweet collected at 2020-04-24 22:17:37+00:00\n",
      "Tweet collected at 2020-04-24 22:17:42+00:00\n",
      "Tweet collected at 2020-04-24 22:17:44+00:00\n",
      "Tweet collected at 2020-04-24 22:17:45+00:00\n",
      "Tweet collected at 2020-04-24 22:17:48+00:00\n",
      "Tweet collected at 2020-04-24 22:17:52+00:00\n",
      "Tweet collected at 2020-04-24 22:17:53+00:00\n",
      "Tweet collected at 2020-04-24 22:17:54+00:00\n",
      "Tweet collected at 2020-04-24 22:18:03+00:00\n",
      "Tweet collected at 2020-04-24 22:18:04+00:00\n",
      "Tweet collected at 2020-04-24 22:18:06+00:00\n",
      "Tweet collected at 2020-04-24 22:18:10+00:00\n",
      "Tweet collected at 2020-04-24 22:18:11+00:00\n",
      "Tweet collected at 2020-04-24 22:18:14+00:00\n",
      "Tweet collected at 2020-04-24 22:18:25+00:00\n",
      "Tweet collected at 2020-04-24 22:18:32+00:00\n",
      "Tweet collected at 2020-04-24 22:18:36+00:00\n",
      "Tweet collected at 2020-04-24 22:18:44+00:00\n",
      "Tweet collected at 2020-04-24 22:18:58+00:00\n",
      "Tweet collected at 2020-04-24 22:18:58+00:00\n",
      "Tweet collected at 2020-04-24 22:18:59+00:00\n",
      "Tweet collected at 2020-04-24 22:19:14+00:00\n",
      "Tweet collected at 2020-04-24 22:19:15+00:00\n",
      "Tweet collected at 2020-04-24 22:19:17+00:00\n",
      "Tweet collected at 2020-04-24 22:19:17+00:00\n",
      "Tweet collected at 2020-04-24 22:19:19+00:00\n",
      "Tweet collected at 2020-04-24 22:19:24+00:00\n",
      "Tweet collected at 2020-04-24 22:19:27+00:00\n",
      "Tweet collected at 2020-04-24 22:19:28+00:00\n",
      "Tweet collected at 2020-04-24 22:19:28+00:00\n",
      "Tweet collected at 2020-04-24 22:19:30+00:00\n",
      "Tweet collected at 2020-04-24 22:19:31+00:00\n",
      "Tweet collected at 2020-04-24 22:19:32+00:00\n",
      "Tweet collected at 2020-04-24 22:19:34+00:00\n",
      "Tweet collected at 2020-04-24 22:19:37+00:00\n",
      "Tweet collected at 2020-04-24 22:19:44+00:00\n",
      "Tweet collected at 2020-04-24 22:19:46+00:00\n",
      "Tweet collected at 2020-04-24 22:19:47+00:00\n",
      "Tweet collected at 2020-04-24 22:19:47+00:00\n",
      "Tweet collected at 2020-04-24 22:19:48+00:00\n",
      "Tweet collected at 2020-04-24 22:19:49+00:00\n",
      "Tweet collected at 2020-04-24 22:19:52+00:00\n",
      "Tweet collected at 2020-04-24 22:20:06+00:00\n",
      "Tweet collected at 2020-04-24 22:20:15+00:00\n",
      "Tweet collected at 2020-04-24 22:20:16+00:00\n",
      "Tweet collected at 2020-04-24 22:20:17+00:00\n",
      "Tweet collected at 2020-04-24 22:20:17+00:00\n",
      "Tweet collected at 2020-04-24 22:20:23+00:00\n",
      "Tweet collected at 2020-04-24 22:20:25+00:00\n",
      "Tweet collected at 2020-04-24 22:20:31+00:00\n",
      "Tweet collected at 2020-04-24 22:20:35+00:00\n",
      "Tweet collected at 2020-04-24 22:20:37+00:00\n",
      "Tweet collected at 2020-04-24 22:20:37+00:00\n",
      "Tweet collected at 2020-04-24 22:20:41+00:00\n",
      "Tweet collected at 2020-04-24 22:20:54+00:00\n",
      "Tweet collected at 2020-04-24 22:20:56+00:00\n",
      "Tweet collected at 2020-04-24 22:21:05+00:00\n",
      "Tweet collected at 2020-04-24 22:21:07+00:00\n",
      "Tweet collected at 2020-04-24 22:21:08+00:00\n",
      "Tweet collected at 2020-04-24 22:21:10+00:00\n",
      "Tweet collected at 2020-04-24 22:21:13+00:00\n",
      "Tweet collected at 2020-04-24 22:21:13+00:00\n",
      "Tweet collected at 2020-04-24 22:21:17+00:00\n",
      "Tweet collected at 2020-04-24 22:21:18+00:00\n",
      "Tweet collected at 2020-04-24 22:21:19+00:00\n",
      "Tweet collected at 2020-04-24 22:21:22+00:00\n",
      "Tweet collected at 2020-04-24 22:21:23+00:00\n",
      "Tweet collected at 2020-04-24 22:21:25+00:00\n",
      "Tweet collected at 2020-04-24 22:21:25+00:00\n",
      "Tweet collected at 2020-04-24 22:21:28+00:00\n",
      "Tweet collected at 2020-04-24 22:21:35+00:00\n",
      "Tweet collected at 2020-04-24 22:21:53+00:00\n",
      "Tweet collected at 2020-04-24 22:21:55+00:00\n",
      "Tweet collected at 2020-04-24 22:21:58+00:00\n",
      "Tweet collected at 2020-04-24 22:21:59+00:00\n",
      "Tweet collected at 2020-04-24 22:22:01+00:00\n",
      "Tweet collected at 2020-04-24 22:22:01+00:00\n",
      "Tweet collected at 2020-04-24 22:22:04+00:00\n",
      "Tweet collected at 2020-04-24 22:22:11+00:00\n",
      "Tweet collected at 2020-04-24 22:22:19+00:00\n",
      "Tweet collected at 2020-04-24 22:22:22+00:00\n",
      "Tweet collected at 2020-04-24 22:22:25+00:00\n",
      "Tweet collected at 2020-04-24 22:22:25+00:00\n",
      "Tweet collected at 2020-04-24 22:22:27+00:00\n",
      "Tweet collected at 2020-04-24 22:22:29+00:00\n",
      "Tweet collected at 2020-04-24 22:22:33+00:00\n",
      "Tweet collected at 2020-04-24 22:22:43+00:00\n",
      "Tweet collected at 2020-04-24 22:22:44+00:00\n",
      "Tweet collected at 2020-04-24 22:22:46+00:00\n",
      "Tweet collected at 2020-04-24 22:22:47+00:00\n",
      "Tweet collected at 2020-04-24 22:22:59+00:00\n",
      "Tweet collected at 2020-04-24 22:23:01+00:00\n",
      "Tweet collected at 2020-04-24 22:23:06+00:00\n",
      "Tweet collected at 2020-04-24 22:23:07+00:00\n",
      "Tweet collected at 2020-04-24 22:23:17+00:00\n",
      "Tweet collected at 2020-04-24 22:23:21+00:00\n",
      "Tweet collected at 2020-04-24 22:23:23+00:00\n",
      "Tweet collected at 2020-04-24 22:23:29+00:00\n",
      "Tweet collected at 2020-04-24 22:23:32+00:00\n",
      "Tweet collected at 2020-04-24 22:23:32+00:00\n",
      "Tweet collected at 2020-04-24 22:23:34+00:00\n",
      "Tweet collected at 2020-04-24 22:23:38+00:00\n",
      "Tweet collected at 2020-04-24 22:23:39+00:00\n",
      "Tweet collected at 2020-04-24 22:23:46+00:00\n",
      "Tweet collected at 2020-04-24 22:23:47+00:00\n",
      "Tweet collected at 2020-04-24 22:23:51+00:00\n",
      "Tweet collected at 2020-04-24 22:23:56+00:00\n",
      "Tweet collected at 2020-04-24 22:24:00+00:00\n",
      "Tweet collected at 2020-04-24 22:24:01+00:00\n",
      "Tweet collected at 2020-04-24 22:24:04+00:00\n",
      "Tweet collected at 2020-04-24 22:24:06+00:00\n",
      "Tweet collected at 2020-04-24 22:24:07+00:00\n",
      "Tweet collected at 2020-04-24 22:24:13+00:00\n",
      "Tweet collected at 2020-04-24 22:24:15+00:00\n",
      "Tweet collected at 2020-04-24 22:24:17+00:00\n",
      "Tweet collected at 2020-04-24 22:24:26+00:00\n",
      "Tweet collected at 2020-04-24 22:24:27+00:00\n",
      "Tweet collected at 2020-04-24 22:24:29+00:00\n",
      "Tweet collected at 2020-04-24 22:24:30+00:00\n",
      "Tweet collected at 2020-04-24 22:24:31+00:00\n",
      "Tweet collected at 2020-04-24 22:24:33+00:00\n",
      "Tweet collected at 2020-04-24 22:24:34+00:00\n",
      "Tweet collected at 2020-04-24 22:24:36+00:00\n",
      "Tweet collected at 2020-04-24 22:24:37+00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet collected at 2020-04-24 22:24:39+00:00\n",
      "Tweet collected at 2020-04-24 22:24:46+00:00\n",
      "Tweet collected at 2020-04-24 22:24:56+00:00\n",
      "Tweet collected at 2020-04-24 22:24:58+00:00\n",
      "Tweet collected at 2020-04-24 22:25:00+00:00\n",
      "Tweet collected at 2020-04-24 22:25:03+00:00\n",
      "Tweet collected at 2020-04-24 22:25:06+00:00\n",
      "Tweet collected at 2020-04-24 22:25:06+00:00\n",
      "Tweet collected at 2020-04-24 22:25:06+00:00\n",
      "Tweet collected at 2020-04-24 22:25:09+00:00\n",
      "Tweet collected at 2020-04-24 22:25:16+00:00\n",
      "Tweet collected at 2020-04-24 22:25:16+00:00\n",
      "Tweet collected at 2020-04-24 22:25:17+00:00\n",
      "Tweet collected at 2020-04-24 22:25:27+00:00\n",
      "Tweet collected at 2020-04-24 22:25:28+00:00\n",
      "Tweet collected at 2020-04-24 22:25:32+00:00\n",
      "Tweet collected at 2020-04-24 22:25:35+00:00\n",
      "Tweet collected at 2020-04-24 22:25:43+00:00\n",
      "Tweet collected at 2020-04-24 22:25:45+00:00\n",
      "Tweet collected at 2020-04-24 22:25:45+00:00\n",
      "Tweet collected at 2020-04-24 22:25:51+00:00\n",
      "Tweet collected at 2020-04-24 22:25:55+00:00\n",
      "Tweet collected at 2020-04-24 22:25:58+00:00\n",
      "Tweet collected at 2020-04-24 22:26:02+00:00\n",
      "Tweet collected at 2020-04-24 22:26:05+00:00\n",
      "Tweet collected at 2020-04-24 22:26:12+00:00\n",
      "Tweet collected at 2020-04-24 22:26:15+00:00\n",
      "Tweet collected at 2020-04-24 22:26:20+00:00\n",
      "Tweet collected at 2020-04-24 22:26:22+00:00\n",
      "Tweet collected at 2020-04-24 22:26:23+00:00\n",
      "Tweet collected at 2020-04-24 22:26:24+00:00\n",
      "Tweet collected at 2020-04-24 22:26:45+00:00\n",
      "Tweet collected at 2020-04-24 22:26:46+00:00\n",
      "Tweet collected at 2020-04-24 22:26:47+00:00\n",
      "Tweet collected at 2020-04-24 22:26:49+00:00\n",
      "Tweet collected at 2020-04-24 22:26:54+00:00\n",
      "Tweet collected at 2020-04-24 22:26:58+00:00\n",
      "Tweet collected at 2020-04-24 22:27:05+00:00\n",
      "Tweet collected at 2020-04-24 22:27:06+00:00\n",
      "Tweet collected at 2020-04-24 22:27:08+00:00\n",
      "Tweet collected at 2020-04-24 22:27:09+00:00\n",
      "Tweet collected at 2020-04-24 22:27:10+00:00\n",
      "Tweet collected at 2020-04-24 22:27:19+00:00\n",
      "Tweet collected at 2020-04-24 22:27:21+00:00\n",
      "Tweet collected at 2020-04-24 22:27:22+00:00\n",
      "Tweet collected at 2020-04-24 22:27:22+00:00\n",
      "Tweet collected at 2020-04-24 22:27:28+00:00\n",
      "Tweet collected at 2020-04-24 22:27:30+00:00\n",
      "Tweet collected at 2020-04-24 22:27:31+00:00\n",
      "Tweet collected at 2020-04-24 22:27:31+00:00\n",
      "Tweet collected at 2020-04-24 22:27:35+00:00\n",
      "Tweet collected at 2020-04-24 22:27:37+00:00\n",
      "Tweet collected at 2020-04-24 22:27:38+00:00\n",
      "Tweet collected at 2020-04-24 22:27:41+00:00\n",
      "Tweet collected at 2020-04-24 22:27:47+00:00\n",
      "Tweet collected at 2020-04-24 22:27:52+00:00\n",
      "Tweet collected at 2020-04-24 22:28:02+00:00\n",
      "Tweet collected at 2020-04-24 22:28:13+00:00\n",
      "Tweet collected at 2020-04-24 22:28:21+00:00\n",
      "Tweet collected at 2020-04-24 22:28:22+00:00\n",
      "Tweet collected at 2020-04-24 22:28:24+00:00\n",
      "Tweet collected at 2020-04-24 22:28:25+00:00\n",
      "Tweet collected at 2020-04-24 22:28:26+00:00\n",
      "Tweet collected at 2020-04-24 22:28:26+00:00\n",
      "Tweet collected at 2020-04-24 22:28:34+00:00\n",
      "Tweet collected at 2020-04-24 22:28:40+00:00\n",
      "Tweet collected at 2020-04-24 22:28:46+00:00\n",
      "Tweet collected at 2020-04-24 22:29:01+00:00\n",
      "Tweet collected at 2020-04-24 22:29:00+00:00\n",
      "Tweet collected at 2020-04-24 22:29:03+00:00\n",
      "Tweet collected at 2020-04-24 22:29:04+00:00\n",
      "Tweet collected at 2020-04-24 22:29:04+00:00\n",
      "Tweet collected at 2020-04-24 22:29:08+00:00\n",
      "Tweet collected at 2020-04-24 22:29:09+00:00\n",
      "Tweet collected at 2020-04-24 22:29:11+00:00\n",
      "Tweet collected at 2020-04-24 22:29:12+00:00\n",
      "Tweet collected at 2020-04-24 22:29:15+00:00\n",
      "Tweet collected at 2020-04-24 22:29:17+00:00\n",
      "Tweet collected at 2020-04-24 22:29:19+00:00\n",
      "Tweet collected at 2020-04-24 22:29:23+00:00\n",
      "Tweet collected at 2020-04-24 22:29:28+00:00\n",
      "Tweet collected at 2020-04-24 22:29:29+00:00\n",
      "Tweet collected at 2020-04-24 22:29:36+00:00\n",
      "Tweet collected at 2020-04-24 22:29:37+00:00\n",
      "Tweet collected at 2020-04-24 22:29:37+00:00\n",
      "Tweet collected at 2020-04-24 22:29:38+00:00\n",
      "Tweet collected at 2020-04-24 22:29:39+00:00\n",
      "Tweet collected at 2020-04-24 22:29:41+00:00\n",
      "Tweet collected at 2020-04-24 22:29:44+00:00\n",
      "Tweet collected at 2020-04-24 22:29:45+00:00\n",
      "Tweet collected at 2020-04-24 22:29:51+00:00\n",
      "Tweet collected at 2020-04-24 22:29:53+00:00\n",
      "Tweet collected at 2020-04-24 22:29:57+00:00\n",
      "Tweet collected at 2020-04-24 22:30:03+00:00\n",
      "Tweet collected at 2020-04-24 22:30:04+00:00\n",
      "Tweet collected at 2020-04-24 22:30:05+00:00\n",
      "Tweet collected at 2020-04-24 22:30:16+00:00\n",
      "Tweet collected at 2020-04-24 22:30:17+00:00\n",
      "Tweet collected at 2020-04-24 22:30:32+00:00\n",
      "Tweet collected at 2020-04-24 22:30:33+00:00\n",
      "Tweet collected at 2020-04-24 22:30:45+00:00\n",
      "Tweet collected at 2020-04-24 22:30:45+00:00\n",
      "Tweet collected at 2020-04-24 22:30:47+00:00\n",
      "Tweet collected at 2020-04-24 22:31:02+00:00\n",
      "Tweet collected at 2020-04-24 22:31:04+00:00\n",
      "Tweet collected at 2020-04-24 22:31:06+00:00\n",
      "Tweet collected at 2020-04-24 22:31:07+00:00\n",
      "Tweet collected at 2020-04-24 22:31:07+00:00\n",
      "Tweet collected at 2020-04-24 22:31:10+00:00\n",
      "Tweet collected at 2020-04-24 22:31:10+00:00\n",
      "Tweet collected at 2020-04-24 22:31:16+00:00\n",
      "Tweet collected at 2020-04-24 22:31:17+00:00\n",
      "Tweet collected at 2020-04-24 22:31:20+00:00\n",
      "Tweet collected at 2020-04-24 22:31:20+00:00\n",
      "Tweet collected at 2020-04-24 22:31:25+00:00\n",
      "Tweet collected at 2020-04-24 22:31:34+00:00\n",
      "Tweet collected at 2020-04-24 22:31:34+00:00\n",
      "Tweet collected at 2020-04-24 22:31:34+00:00\n",
      "Tweet collected at 2020-04-24 22:31:37+00:00\n",
      "Tweet collected at 2020-04-24 22:31:39+00:00\n",
      "Tweet collected at 2020-04-24 22:31:43+00:00\n",
      "Tweet collected at 2020-04-24 22:31:56+00:00\n",
      "Tweet collected at 2020-04-24 22:31:58+00:00\n",
      "Tweet collected at 2020-04-24 22:32:06+00:00\n",
      "Tweet collected at 2020-04-24 22:32:06+00:00\n",
      "Tweet collected at 2020-04-24 22:32:07+00:00\n",
      "Tweet collected at 2020-04-24 22:32:15+00:00\n",
      "Tweet collected at 2020-04-24 22:32:18+00:00\n",
      "Tweet collected at 2020-04-24 22:32:21+00:00\n",
      "Tweet collected at 2020-04-24 22:32:22+00:00\n",
      "Tweet collected at 2020-04-24 22:32:28+00:00\n",
      "Tweet collected at 2020-04-24 22:32:33+00:00\n",
      "Tweet collected at 2020-04-24 22:32:34+00:00\n",
      "Tweet collected at 2020-04-24 22:32:37+00:00\n",
      "Tweet collected at 2020-04-24 22:32:43+00:00\n",
      "Tweet collected at 2020-04-24 22:32:45+00:00\n",
      "Tweet collected at 2020-04-24 22:32:49+00:00\n",
      "Tweet collected at 2020-04-24 22:32:49+00:00\n",
      "Tweet collected at 2020-04-24 22:32:55+00:00\n",
      "Tweet collected at 2020-04-24 22:32:55+00:00\n",
      "Tweet collected at 2020-04-24 22:32:59+00:00\n",
      "Tweet collected at 2020-04-24 22:33:02+00:00\n",
      "Tweet collected at 2020-04-24 22:33:02+00:00\n",
      "Tweet collected at 2020-04-24 22:33:06+00:00\n",
      "Tweet collected at 2020-04-24 22:33:07+00:00\n",
      "Tweet collected at 2020-04-24 22:33:14+00:00\n",
      "Tweet collected at 2020-04-24 22:33:24+00:00\n",
      "Tweet collected at 2020-04-24 22:33:26+00:00\n",
      "Tweet collected at 2020-04-24 22:33:26+00:00\n",
      "Tweet collected at 2020-04-24 22:33:27+00:00\n",
      "Tweet collected at 2020-04-24 22:33:28+00:00\n",
      "Tweet collected at 2020-04-24 22:33:31+00:00\n",
      "Tweet collected at 2020-04-24 22:33:39+00:00\n",
      "Tweet collected at 2020-04-24 22:33:39+00:00\n",
      "Tweet collected at 2020-04-24 22:33:40+00:00\n",
      "Tweet collected at 2020-04-24 22:33:44+00:00\n",
      "Tweet collected at 2020-04-24 22:33:50+00:00\n",
      "Tweet collected at 2020-04-24 22:33:52+00:00\n",
      "Tweet collected at 2020-04-24 22:33:56+00:00\n",
      "Tweet collected at 2020-04-24 22:34:01+00:00\n",
      "Tweet collected at 2020-04-24 22:34:03+00:00\n",
      "Tweet collected at 2020-04-24 22:34:04+00:00\n",
      "Tweet collected at 2020-04-24 22:34:11+00:00\n",
      "Tweet collected at 2020-04-24 22:34:16+00:00\n",
      "Tweet collected at 2020-04-24 22:34:19+00:00\n",
      "Tweet collected at 2020-04-24 22:34:19+00:00\n",
      "Tweet collected at 2020-04-24 22:34:21+00:00\n",
      "Tweet collected at 2020-04-24 22:34:21+00:00\n",
      "Tweet collected at 2020-04-24 22:34:25+00:00\n",
      "Tweet collected at 2020-04-24 22:34:26+00:00\n",
      "Tweet collected at 2020-04-24 22:34:27+00:00\n",
      "Tweet collected at 2020-04-24 22:34:28+00:00\n",
      "Tweet collected at 2020-04-24 22:34:31+00:00\n",
      "Tweet collected at 2020-04-24 22:34:47+00:00\n",
      "Tweet collected at 2020-04-24 22:35:02+00:00\n",
      "Tweet collected at 2020-04-24 22:35:05+00:00\n",
      "Tweet collected at 2020-04-24 22:35:06+00:00\n",
      "Tweet collected at 2020-04-24 22:35:12+00:00\n",
      "Tweet collected at 2020-04-24 22:35:14+00:00\n",
      "Tweet collected at 2020-04-24 22:35:16+00:00\n",
      "Tweet collected at 2020-04-24 22:35:23+00:00\n",
      "Tweet collected at 2020-04-24 22:35:24+00:00\n",
      "Tweet collected at 2020-04-24 22:35:25+00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet collected at 2020-04-24 22:35:39+00:00\n",
      "Tweet collected at 2020-04-24 22:35:50+00:00\n",
      "Tweet collected at 2020-04-24 22:35:50+00:00\n",
      "Tweet collected at 2020-04-24 22:35:52+00:00\n",
      "Tweet collected at 2020-04-24 22:35:58+00:00\n",
      "Tweet collected at 2020-04-24 22:35:59+00:00\n",
      "Tweet collected at 2020-04-24 22:36:12+00:00\n",
      "Tweet collected at 2020-04-24 22:36:16+00:00\n",
      "Tweet collected at 2020-04-24 22:36:17+00:00\n",
      "Tweet collected at 2020-04-24 22:36:22+00:00\n",
      "Tweet collected at 2020-04-24 22:36:23+00:00\n",
      "Tweet collected at 2020-04-24 22:36:28+00:00\n",
      "Tweet collected at 2020-04-24 22:36:28+00:00\n",
      "Tweet collected at 2020-04-24 22:36:32+00:00\n",
      "Tweet collected at 2020-04-24 22:36:34+00:00\n",
      "Tweet collected at 2020-04-24 22:36:34+00:00\n",
      "Tweet collected at 2020-04-24 22:36:36+00:00\n",
      "Tweet collected at 2020-04-24 22:36:37+00:00\n",
      "Tweet collected at 2020-04-24 22:36:42+00:00\n",
      "Tweet collected at 2020-04-24 22:36:44+00:00\n",
      "Tweet collected at 2020-04-24 22:36:46+00:00\n",
      "Tweet collected at 2020-04-24 22:36:55+00:00\n",
      "Tweet collected at 2020-04-24 22:36:58+00:00\n",
      "Tweet collected at 2020-04-24 22:37:00+00:00\n",
      "Tweet collected at 2020-04-24 22:37:03+00:00\n",
      "Tweet collected at 2020-04-24 22:37:08+00:00\n",
      "Tweet collected at 2020-04-24 22:37:09+00:00\n",
      "Tweet collected at 2020-04-24 22:37:15+00:00\n",
      "Tweet collected at 2020-04-24 22:37:18+00:00\n",
      "Tweet collected at 2020-04-24 22:37:22+00:00\n",
      "Tweet collected at 2020-04-24 22:37:27+00:00\n",
      "Tweet collected at 2020-04-24 22:37:29+00:00\n",
      "Tweet collected at 2020-04-24 22:37:29+00:00\n",
      "Tweet collected at 2020-04-24 22:37:51+00:00\n",
      "Tweet collected at 2020-04-24 22:37:56+00:00\n",
      "Tweet collected at 2020-04-24 22:37:56+00:00\n",
      "Tweet collected at 2020-04-24 22:37:58+00:00\n",
      "Tweet collected at 2020-04-24 22:38:04+00:00\n",
      "Tweet collected at 2020-04-24 22:38:04+00:00\n",
      "Tweet collected at 2020-04-24 22:38:05+00:00\n",
      "Tweet collected at 2020-04-24 22:38:11+00:00\n",
      "Tweet collected at 2020-04-24 22:38:21+00:00\n",
      "Tweet collected at 2020-04-24 22:38:22+00:00\n",
      "Tweet collected at 2020-04-24 22:38:25+00:00\n",
      "Tweet collected at 2020-04-24 22:38:26+00:00\n",
      "Tweet collected at 2020-04-24 22:38:31+00:00\n",
      "Tweet collected at 2020-04-24 22:38:38+00:00\n",
      "Tweet collected at 2020-04-24 22:38:56+00:00\n",
      "Tweet collected at 2020-04-24 22:38:57+00:00\n",
      "Tweet collected at 2020-04-24 22:38:57+00:00\n",
      "Tweet collected at 2020-04-24 22:39:04+00:00\n",
      "Tweet collected at 2020-04-24 22:39:05+00:00\n",
      "Tweet collected at 2020-04-24 22:39:06+00:00\n",
      "Tweet collected at 2020-04-24 22:39:20+00:00\n",
      "Tweet collected at 2020-04-24 22:39:23+00:00\n",
      "Tweet collected at 2020-04-24 22:39:26+00:00\n",
      "Tweet collected at 2020-04-24 22:39:33+00:00\n",
      "Tweet collected at 2020-04-24 22:39:35+00:00\n",
      "Tweet collected at 2020-04-24 22:39:37+00:00\n",
      "Tweet collected at 2020-04-24 22:39:44+00:00\n",
      "Tweet collected at 2020-04-24 22:39:47+00:00\n",
      "Tweet collected at 2020-04-24 22:39:47+00:00\n",
      "Tweet collected at 2020-04-24 22:39:48+00:00\n",
      "Tweet collected at 2020-04-24 22:39:58+00:00\n",
      "Tweet collected at 2020-04-24 22:39:59+00:00\n",
      "Tweet collected at 2020-04-24 22:40:01+00:00\n",
      "Tweet collected at 2020-04-24 22:40:01+00:00\n",
      "Tweet collected at 2020-04-24 22:40:07+00:00\n",
      "Tweet collected at 2020-04-24 22:40:16+00:00\n",
      "Tweet collected at 2020-04-24 22:40:18+00:00\n",
      "Tweet collected at 2020-04-24 22:40:20+00:00\n",
      "Tweet collected at 2020-04-24 22:40:21+00:00\n",
      "Tweet collected at 2020-04-24 22:40:24+00:00\n",
      "Tweet collected at 2020-04-24 22:40:30+00:00\n",
      "Tweet collected at 2020-04-24 22:40:31+00:00\n",
      "Tweet collected at 2020-04-24 22:40:32+00:00\n",
      "Tweet collected at 2020-04-24 22:40:35+00:00\n",
      "Tweet collected at 2020-04-24 22:40:37+00:00\n",
      "Tweet collected at 2020-04-24 22:40:38+00:00\n",
      "Tweet collected at 2020-04-24 22:40:39+00:00\n",
      "Tweet collected at 2020-04-24 22:40:45+00:00\n",
      "Tweet collected at 2020-04-24 22:40:46+00:00\n",
      "Tweet collected at 2020-04-24 22:40:49+00:00\n",
      "Tweet collected at 2020-04-24 22:41:00+00:00\n",
      "Tweet collected at 2020-04-24 22:40:57+00:00\n",
      "Tweet collected at 2020-04-24 22:40:59+00:00\n",
      "Tweet collected at 2020-04-24 22:41:04+00:00\n",
      "Tweet collected at 2020-04-24 22:41:06+00:00\n",
      "Tweet collected at 2020-04-24 22:41:11+00:00\n",
      "Tweet collected at 2020-04-24 22:41:20+00:00\n",
      "Tweet collected at 2020-04-24 22:41:20+00:00\n",
      "Tweet collected at 2020-04-24 22:41:20+00:00\n",
      "Tweet collected at 2020-04-24 22:41:23+00:00\n",
      "Tweet collected at 2020-04-24 22:41:30+00:00\n",
      "Tweet collected at 2020-04-24 22:41:31+00:00\n",
      "Tweet collected at 2020-04-24 22:41:33+00:00\n",
      "Tweet collected at 2020-04-24 22:41:36+00:00\n",
      "Tweet collected at 2020-04-24 22:41:39+00:00\n",
      "Tweet collected at 2020-04-24 22:41:40+00:00\n",
      "Tweet collected at 2020-04-24 22:41:43+00:00\n",
      "Tweet collected at 2020-04-24 22:41:59+00:00\n",
      "Tweet collected at 2020-04-24 22:42:06+00:00\n",
      "Tweet collected at 2020-04-24 22:42:06+00:00\n",
      "Tweet collected at 2020-04-24 22:42:08+00:00\n",
      "Tweet collected at 2020-04-24 22:42:10+00:00\n",
      "Tweet collected at 2020-04-24 22:42:12+00:00\n",
      "Tweet collected at 2020-04-24 22:42:18+00:00\n",
      "Tweet collected at 2020-04-24 22:42:21+00:00\n",
      "Tweet collected at 2020-04-24 22:42:31+00:00\n",
      "Tweet collected at 2020-04-24 22:42:34+00:00\n",
      "Tweet collected at 2020-04-24 22:42:34+00:00\n",
      "Tweet collected at 2020-04-24 22:42:41+00:00\n",
      "Tweet collected at 2020-04-24 22:42:44+00:00\n",
      "Tweet collected at 2020-04-24 22:42:49+00:00\n",
      "Tweet collected at 2020-04-24 22:42:54+00:00\n",
      "Tweet collected at 2020-04-24 22:43:05+00:00\n",
      "Tweet collected at 2020-04-24 22:43:07+00:00\n",
      "Tweet collected at 2020-04-24 22:43:09+00:00\n",
      "Tweet collected at 2020-04-24 22:43:22+00:00\n",
      "Tweet collected at 2020-04-24 22:43:23+00:00\n",
      "Tweet collected at 2020-04-24 22:43:30+00:00\n",
      "Tweet collected at 2020-04-24 22:43:34+00:00\n",
      "Tweet collected at 2020-04-24 22:43:36+00:00\n",
      "Tweet collected at 2020-04-24 22:43:40+00:00\n",
      "Tweet collected at 2020-04-24 22:43:43+00:00\n",
      "Tweet collected at 2020-04-24 22:43:45+00:00\n",
      "Tweet collected at 2020-04-24 22:43:49+00:00\n",
      "Tweet collected at 2020-04-24 22:43:52+00:00\n",
      "Tweet collected at 2020-04-24 22:43:53+00:00\n",
      "Tweet collected at 2020-04-24 22:43:57+00:00\n",
      "Tweet collected at 2020-04-24 22:44:01+00:00\n",
      "Tweet collected at 2020-04-24 22:44:02+00:00\n",
      "Tweet collected at 2020-04-24 22:44:19+00:00\n",
      "Tweet collected at 2020-04-24 22:44:21+00:00\n",
      "Tweet collected at 2020-04-24 22:44:21+00:00\n",
      "Tweet collected at 2020-04-24 22:44:27+00:00\n",
      "Tweet collected at 2020-04-24 22:44:28+00:00\n",
      "Tweet collected at 2020-04-24 22:44:30+00:00\n",
      "Tweet collected at 2020-04-24 22:44:31+00:00\n",
      "Tweet collected at 2020-04-24 22:44:40+00:00\n",
      "Tweet collected at 2020-04-24 22:44:41+00:00\n",
      "Tweet collected at 2020-04-24 22:44:44+00:00\n",
      "Tweet collected at 2020-04-24 22:44:44+00:00\n",
      "Tweet collected at 2020-04-24 22:44:48+00:00\n",
      "Tweet collected at 2020-04-24 22:44:48+00:00\n",
      "Tweet collected at 2020-04-24 22:44:56+00:00\n",
      "Tweet collected at 2020-04-24 22:45:03+00:00\n",
      "Tweet collected at 2020-04-24 22:45:05+00:00\n",
      "Tweet collected at 2020-04-24 22:45:17+00:00\n",
      "Tweet collected at 2020-04-24 22:45:29+00:00\n",
      "Tweet collected at 2020-04-24 22:45:37+00:00\n",
      "Tweet collected at 2020-04-24 22:45:38+00:00\n",
      "Tweet collected at 2020-04-24 22:45:48+00:00\n",
      "Tweet collected at 2020-04-24 22:46:04+00:00\n",
      "Tweet collected at 2020-04-24 22:46:05+00:00\n",
      "Tweet collected at 2020-04-24 22:46:07+00:00\n",
      "Tweet collected at 2020-04-24 22:46:11+00:00\n",
      "Tweet collected at 2020-04-24 22:46:13+00:00\n",
      "Tweet collected at 2020-04-24 22:46:14+00:00\n",
      "Tweet collected at 2020-04-24 22:46:21+00:00\n",
      "Tweet collected at 2020-04-24 22:46:30+00:00\n",
      "Tweet collected at 2020-04-24 22:46:40+00:00\n",
      "Tweet collected at 2020-04-24 22:46:46+00:00\n",
      "Tweet collected at 2020-04-24 22:46:55+00:00\n",
      "Tweet collected at 2020-04-24 22:46:55+00:00\n",
      "Tweet collected at 2020-04-24 22:47:02+00:00\n",
      "Tweet collected at 2020-04-24 22:47:08+00:00\n",
      "Tweet collected at 2020-04-24 22:47:11+00:00\n",
      "Tweet collected at 2020-04-24 22:47:13+00:00\n",
      "Tweet collected at 2020-04-24 22:47:14+00:00\n",
      "Tweet collected at 2020-04-24 22:47:18+00:00\n",
      "Tweet collected at 2020-04-24 22:47:19+00:00\n",
      "Tweet collected at 2020-04-24 22:47:22+00:00\n",
      "Tweet collected at 2020-04-24 22:47:22+00:00\n",
      "Tweet collected at 2020-04-24 22:47:28+00:00\n",
      "Tweet collected at 2020-04-24 22:47:33+00:00\n",
      "Tweet collected at 2020-04-24 22:47:36+00:00\n",
      "Tweet collected at 2020-04-24 22:47:47+00:00\n",
      "Tweet collected at 2020-04-24 22:47:48+00:00\n",
      "Tweet collected at 2020-04-24 22:47:53+00:00\n",
      "Tweet collected at 2020-04-24 22:47:57+00:00\n",
      "Tweet collected at 2020-04-24 22:48:01+00:00\n",
      "Tweet collected at 2020-04-24 22:48:02+00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet collected at 2020-04-24 22:48:04+00:00\n",
      "Tweet collected at 2020-04-24 22:48:08+00:00\n",
      "Tweet collected at 2020-04-24 22:48:17+00:00\n",
      "Tweet collected at 2020-04-24 22:48:20+00:00\n",
      "Tweet collected at 2020-04-24 22:48:24+00:00\n",
      "Tweet collected at 2020-04-24 22:48:25+00:00\n",
      "Tweet collected at 2020-04-24 22:48:28+00:00\n",
      "Tweet collected at 2020-04-24 22:48:35+00:00\n",
      "Tweet collected at 2020-04-24 22:48:36+00:00\n",
      "Tweet collected at 2020-04-24 22:48:38+00:00\n",
      "Tweet collected at 2020-04-24 22:48:38+00:00\n",
      "Tweet collected at 2020-04-24 22:48:44+00:00\n",
      "Tweet collected at 2020-04-24 22:48:49+00:00\n",
      "Tweet collected at 2020-04-24 22:48:49+00:00\n",
      "Tweet collected at 2020-04-24 22:48:53+00:00\n",
      "Tweet collected at 2020-04-24 22:48:53+00:00\n",
      "Tweet collected at 2020-04-24 22:48:55+00:00\n",
      "Tweet collected at 2020-04-24 22:48:55+00:00\n",
      "Tweet collected at 2020-04-24 22:49:00+00:00\n",
      "Tweet collected at 2020-04-24 22:49:03+00:00\n",
      "Tweet collected at 2020-04-24 22:49:10+00:00\n",
      "Tweet collected at 2020-04-24 22:49:10+00:00\n",
      "Tweet collected at 2020-04-24 22:49:13+00:00\n",
      "Tweet collected at 2020-04-24 22:49:14+00:00\n",
      "Tweet collected at 2020-04-24 22:49:17+00:00\n",
      "Tweet collected at 2020-04-24 22:49:27+00:00\n",
      "Tweet collected at 2020-04-24 22:49:30+00:00\n",
      "Tweet collected at 2020-04-24 22:49:37+00:00\n",
      "Tweet collected at 2020-04-24 22:49:37+00:00\n",
      "Tweet collected at 2020-04-24 22:49:38+00:00\n",
      "Tweet collected at 2020-04-24 22:49:41+00:00\n",
      "Tweet collected at 2020-04-24 22:49:42+00:00\n",
      "Tweet collected at 2020-04-24 22:49:49+00:00\n",
      "Tweet collected at 2020-04-24 22:49:51+00:00\n",
      "Tweet collected at 2020-04-24 22:49:52+00:00\n",
      "Tweet collected at 2020-04-24 22:49:53+00:00\n",
      "Tweet collected at 2020-04-24 22:49:57+00:00\n",
      "Tweet collected at 2020-04-24 22:50:01+00:00\n",
      "Tweet collected at 2020-04-24 22:50:04+00:00\n",
      "Tweet collected at 2020-04-24 22:50:07+00:00\n",
      "Tweet collected at 2020-04-24 22:50:08+00:00\n",
      "Tweet collected at 2020-04-24 22:50:10+00:00\n",
      "Tweet collected at 2020-04-24 22:50:15+00:00\n",
      "Tweet collected at 2020-04-24 22:50:21+00:00\n",
      "Tweet collected at 2020-04-24 22:50:22+00:00\n",
      "Tweet collected at 2020-04-24 22:50:28+00:00\n",
      "Tweet collected at 2020-04-24 22:50:29+00:00\n",
      "Tweet collected at 2020-04-24 22:50:30+00:00\n",
      "Tweet collected at 2020-04-24 22:50:38+00:00\n",
      "Tweet collected at 2020-04-24 22:50:43+00:00\n",
      "Tweet collected at 2020-04-24 22:50:50+00:00\n",
      "Tweet collected at 2020-04-24 22:50:53+00:00\n",
      "Tweet collected at 2020-04-24 22:51:01+00:00\n",
      "Tweet collected at 2020-04-24 22:51:07+00:00\n",
      "Tweet collected at 2020-04-24 22:51:08+00:00\n",
      "Tweet collected at 2020-04-24 22:51:08+00:00\n",
      "Tweet collected at 2020-04-24 22:51:27+00:00\n",
      "Tweet collected at 2020-04-24 22:51:30+00:00\n",
      "Tweet collected at 2020-04-24 22:51:32+00:00\n",
      "Tweet collected at 2020-04-24 22:51:35+00:00\n",
      "Tweet collected at 2020-04-24 22:51:36+00:00\n",
      "Tweet collected at 2020-04-24 22:51:41+00:00\n",
      "Tweet collected at 2020-04-24 22:51:47+00:00\n",
      "Tweet collected at 2020-04-24 22:51:48+00:00\n",
      "Tweet collected at 2020-04-24 22:51:48+00:00\n",
      "Tweet collected at 2020-04-24 22:51:51+00:00\n",
      "Tweet collected at 2020-04-24 22:52:00+00:00\n",
      "Tweet collected at 2020-04-24 22:52:02+00:00\n",
      "Tweet collected at 2020-04-24 22:52:07+00:00\n",
      "Tweet collected at 2020-04-24 22:52:11+00:00\n",
      "Tweet collected at 2020-04-24 22:52:11+00:00\n",
      "Tweet collected at 2020-04-24 22:52:20+00:00\n",
      "Tweet collected at 2020-04-24 22:52:23+00:00\n",
      "Tweet collected at 2020-04-24 22:52:24+00:00\n",
      "Tweet collected at 2020-04-24 22:52:25+00:00\n",
      "Tweet collected at 2020-04-24 22:52:28+00:00\n",
      "Tweet collected at 2020-04-24 22:52:30+00:00\n",
      "Tweet collected at 2020-04-24 22:52:40+00:00\n",
      "Tweet collected at 2020-04-24 22:52:42+00:00\n",
      "Tweet collected at 2020-04-24 22:52:45+00:00\n",
      "Tweet collected at 2020-04-24 22:52:50+00:00\n",
      "Tweet collected at 2020-04-24 22:52:52+00:00\n",
      "Tweet collected at 2020-04-24 22:52:53+00:00\n",
      "Tweet collected at 2020-04-24 22:52:59+00:00\n",
      "Tweet collected at 2020-04-24 22:52:59+00:00\n",
      "Tweet collected at 2020-04-24 22:52:59+00:00\n",
      "Tweet collected at 2020-04-24 22:53:00+00:00\n",
      "Tweet collected at 2020-04-24 22:53:06+00:00\n",
      "Tweet collected at 2020-04-24 22:53:06+00:00\n",
      "Tweet collected at 2020-04-24 22:53:10+00:00\n",
      "Tweet collected at 2020-04-24 22:53:11+00:00\n",
      "Tweet collected at 2020-04-24 22:53:17+00:00\n",
      "Tweet collected at 2020-04-24 22:53:17+00:00\n",
      "Tweet collected at 2020-04-24 22:53:18+00:00\n",
      "Tweet collected at 2020-04-24 22:53:20+00:00\n",
      "Tweet collected at 2020-04-24 22:53:30+00:00\n",
      "Tweet collected at 2020-04-24 22:53:32+00:00\n",
      "Tweet collected at 2020-04-24 22:53:35+00:00\n",
      "Tweet collected at 2020-04-24 22:53:37+00:00\n",
      "Tweet collected at 2020-04-24 22:53:37+00:00\n",
      "Tweet collected at 2020-04-24 22:53:38+00:00\n",
      "Tweet collected at 2020-04-24 22:53:38+00:00\n",
      "Tweet collected at 2020-04-24 22:53:40+00:00\n",
      "Tweet collected at 2020-04-24 22:53:49+00:00\n",
      "Tweet collected at 2020-04-24 22:53:55+00:00\n",
      "Tweet collected at 2020-04-24 22:53:56+00:00\n",
      "Tweet collected at 2020-04-24 22:53:58+00:00\n",
      "Tweet collected at 2020-04-24 22:54:00+00:00\n",
      "Tweet collected at 2020-04-24 22:54:01+00:00\n",
      "Tweet collected at 2020-04-24 22:54:05+00:00\n",
      "Tweet collected at 2020-04-24 22:54:11+00:00\n",
      "Tweet collected at 2020-04-24 22:54:12+00:00\n",
      "Tweet collected at 2020-04-24 22:54:13+00:00\n",
      "Tweet collected at 2020-04-24 22:54:16+00:00\n",
      "Tweet collected at 2020-04-24 22:54:23+00:00\n",
      "Tweet collected at 2020-04-24 22:54:26+00:00\n",
      "Tweet collected at 2020-04-24 22:54:33+00:00\n",
      "Tweet collected at 2020-04-24 22:54:34+00:00\n",
      "Tweet collected at 2020-04-24 22:54:36+00:00\n",
      "Tweet collected at 2020-04-24 22:54:37+00:00\n",
      "Tweet collected at 2020-04-24 22:54:38+00:00\n",
      "Tweet collected at 2020-04-24 22:54:38+00:00\n",
      "Tweet collected at 2020-04-24 22:54:41+00:00\n",
      "Tweet collected at 2020-04-24 22:54:50+00:00\n",
      "Tweet collected at 2020-04-24 22:54:51+00:00\n",
      "Tweet collected at 2020-04-24 22:54:56+00:00\n",
      "Tweet collected at 2020-04-24 22:54:58+00:00\n",
      "Tweet collected at 2020-04-24 22:55:06+00:00\n",
      "Tweet collected at 2020-04-24 22:55:08+00:00\n",
      "Tweet collected at 2020-04-24 22:55:08+00:00\n",
      "Tweet collected at 2020-04-24 22:55:11+00:00\n",
      "Tweet collected at 2020-04-24 22:55:17+00:00\n",
      "Tweet collected at 2020-04-24 22:55:19+00:00\n",
      "Tweet collected at 2020-04-24 22:55:22+00:00\n",
      "Tweet collected at 2020-04-24 22:55:25+00:00\n",
      "Tweet collected at 2020-04-24 22:55:25+00:00\n",
      "Tweet collected at 2020-04-24 22:55:30+00:00\n",
      "Tweet collected at 2020-04-24 22:55:35+00:00\n",
      "Tweet collected at 2020-04-24 22:55:37+00:00\n",
      "Tweet collected at 2020-04-24 22:55:47+00:00\n",
      "Tweet collected at 2020-04-24 22:55:49+00:00\n",
      "Tweet collected at 2020-04-24 22:55:50+00:00\n",
      "Tweet collected at 2020-04-24 22:55:54+00:00\n",
      "Tweet collected at 2020-04-24 22:56:04+00:00\n",
      "Tweet collected at 2020-04-24 22:56:08+00:00\n",
      "Tweet collected at 2020-04-24 22:56:16+00:00\n",
      "Tweet collected at 2020-04-24 22:56:17+00:00\n",
      "Tweet collected at 2020-04-24 22:56:19+00:00\n",
      "Tweet collected at 2020-04-24 22:56:23+00:00\n",
      "Tweet collected at 2020-04-24 22:56:42+00:00\n",
      "Tweet collected at 2020-04-24 22:56:44+00:00\n",
      "Tweet collected at 2020-04-24 22:56:47+00:00\n",
      "Tweet collected at 2020-04-24 22:56:47+00:00\n",
      "Tweet collected at 2020-04-24 22:56:50+00:00\n",
      "Tweet collected at 2020-04-24 22:56:50+00:00\n",
      "Tweet collected at 2020-04-24 22:57:00+00:00\n",
      "Tweet collected at 2020-04-24 22:57:01+00:00\n",
      "Tweet collected at 2020-04-24 22:57:02+00:00\n",
      "Tweet collected at 2020-04-24 22:57:09+00:00\n",
      "Tweet collected at 2020-04-24 22:57:15+00:00\n",
      "Tweet collected at 2020-04-24 22:57:28+00:00\n",
      "Tweet collected at 2020-04-24 22:57:28+00:00\n",
      "Tweet collected at 2020-04-24 22:57:31+00:00\n",
      "Tweet collected at 2020-04-24 22:57:32+00:00\n",
      "Tweet collected at 2020-04-24 22:57:42+00:00\n",
      "Tweet collected at 2020-04-24 22:57:51+00:00\n",
      "Tweet collected at 2020-04-24 22:58:11+00:00\n",
      "Tweet collected at 2020-04-24 22:58:13+00:00\n",
      "Tweet collected at 2020-04-24 22:58:16+00:00\n",
      "Tweet collected at 2020-04-24 22:58:16+00:00\n",
      "Tweet collected at 2020-04-24 22:58:20+00:00\n",
      "Tweet collected at 2020-04-24 22:58:34+00:00\n",
      "Tweet collected at 2020-04-24 22:58:36+00:00\n",
      "Tweet collected at 2020-04-24 22:58:37+00:00\n",
      "Tweet collected at 2020-04-24 22:58:38+00:00\n",
      "Tweet collected at 2020-04-24 22:58:44+00:00\n",
      "Tweet collected at 2020-04-24 22:58:45+00:00\n",
      "Tweet collected at 2020-04-24 22:58:46+00:00\n",
      "Tweet collected at 2020-04-24 22:58:53+00:00\n",
      "Tweet collected at 2020-04-24 22:58:55+00:00\n",
      "Tweet collected at 2020-04-24 22:59:01+00:00\n",
      "Tweet collected at 2020-04-24 22:59:06+00:00\n",
      "Tweet collected at 2020-04-24 22:59:06+00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet collected at 2020-04-24 22:59:12+00:00\n",
      "Tweet collected at 2020-04-24 22:59:15+00:00\n",
      "Tweet collected at 2020-04-24 22:59:16+00:00\n",
      "Tweet collected at 2020-04-24 22:59:28+00:00\n",
      "Tweet collected at 2020-04-24 22:59:29+00:00\n",
      "Tweet collected at 2020-04-24 22:59:32+00:00\n",
      "Tweet collected at 2020-04-24 22:59:33+00:00\n",
      "Tweet collected at 2020-04-24 22:59:46+00:00\n",
      "Tweet collected at 2020-04-24 22:59:51+00:00\n",
      "Tweet collected at 2020-04-24 22:59:57+00:00\n",
      "Tweet collected at 2020-04-24 22:59:57+00:00\n",
      "Tweet collected at 2020-04-24 23:00:01+00:00\n",
      "Tweet collected at 2020-04-24 23:00:04+00:00\n",
      "Tweet collected at 2020-04-24 23:00:07+00:00\n",
      "Tweet collected at 2020-04-24 23:00:10+00:00\n",
      "Tweet collected at 2020-04-24 23:00:12+00:00\n",
      "Tweet collected at 2020-04-24 23:00:12+00:00\n",
      "Tweet collected at 2020-04-24 23:00:20+00:00\n",
      "Tweet collected at 2020-04-24 23:00:21+00:00\n",
      "Tweet collected at 2020-04-24 23:00:31+00:00\n",
      "Tweet collected at 2020-04-24 23:00:33+00:00\n",
      "Tweet collected at 2020-04-24 23:00:36+00:00\n",
      "Tweet collected at 2020-04-24 23:00:37+00:00\n",
      "Tweet collected at 2020-04-24 23:00:48+00:00\n",
      "Tweet collected at 2020-04-24 23:00:48+00:00\n",
      "Tweet collected at 2020-04-24 23:00:50+00:00\n",
      "Tweet collected at 2020-04-24 23:00:52+00:00\n",
      "Tweet collected at 2020-04-24 23:00:53+00:00\n",
      "Tweet collected at 2020-04-24 23:01:02+00:00\n",
      "Tweet collected at 2020-04-24 23:01:09+00:00\n",
      "Tweet collected at 2020-04-24 23:01:16+00:00\n",
      "Tweet collected at 2020-04-24 23:01:17+00:00\n",
      "Tweet collected at 2020-04-24 23:01:21+00:00\n",
      "Tweet collected at 2020-04-24 23:01:23+00:00\n",
      "Tweet collected at 2020-04-24 23:01:28+00:00\n",
      "Tweet collected at 2020-04-24 23:01:29+00:00\n",
      "Tweet collected at 2020-04-24 23:01:31+00:00\n",
      "Tweet collected at 2020-04-24 23:01:42+00:00\n",
      "Tweet collected at 2020-04-24 23:01:43+00:00\n",
      "Tweet collected at 2020-04-24 23:01:45+00:00\n",
      "Tweet collected at 2020-04-24 23:01:48+00:00\n",
      "Tweet collected at 2020-04-24 23:01:50+00:00\n",
      "Tweet collected at 2020-04-24 23:01:50+00:00\n",
      "Tweet collected at 2020-04-24 23:01:51+00:00\n",
      "Tweet collected at 2020-04-24 23:02:01+00:00\n",
      "Tweet collected at 2020-04-24 23:02:03+00:00\n",
      "Tweet collected at 2020-04-24 23:02:08+00:00\n",
      "Tweet collected at 2020-04-24 23:02:09+00:00\n",
      "Tweet collected at 2020-04-24 23:02:14+00:00\n",
      "Tweet collected at 2020-04-24 23:02:19+00:00\n",
      "Tweet collected at 2020-04-24 23:02:27+00:00\n",
      "Tweet collected at 2020-04-24 23:02:40+00:00\n",
      "Tweet collected at 2020-04-24 23:02:42+00:00\n",
      "Tweet collected at 2020-04-24 23:02:48+00:00\n",
      "Tweet collected at 2020-04-24 23:02:52+00:00\n",
      "Tweet collected at 2020-04-24 23:02:59+00:00\n",
      "Tweet collected at 2020-04-24 23:03:02+00:00\n",
      "Tweet collected at 2020-04-24 23:03:05+00:00\n",
      "Tweet collected at 2020-04-24 23:03:10+00:00\n",
      "Tweet collected at 2020-04-24 23:03:11+00:00\n",
      "Tweet collected at 2020-04-24 23:03:15+00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1821\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1822\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[1;34m(self, ssl, result)\u001b[0m\n\u001b[0;32m   1621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1622\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1623\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c9e7a6e7c288>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'#medicaid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'#medicare'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'#usmedicalinsurance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'#usinsurance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'medic aid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'medicare'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'medicaid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'medic care'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tracking: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mstreamer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filter_level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, is_async)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m                 \u001b[0mstripped_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mline\u001b[0m \u001b[1;31m# line is sometimes None so we need to check here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstripped_line\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mread_line\u001b[1;34m(self, sep)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Close the connection when no data is returned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    552\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m                 \u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;31m# Read the next chunk size from the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chunk size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The read operation timed out'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\urllib3\\util\\wait.py\u001b[0m in \u001b[0;36mwait_for_read\u001b[1;34m(sock, timeout)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msocket\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0mexpired\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \"\"\"\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mwait_for_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\urllib3\\util\\wait.py\u001b[0m in \u001b[0;36mselect_wait_for_socket\u001b[1;34m(sock, read, write, timeout)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;31m# thing.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwcheck\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mrready\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwready\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_retry_on_intr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrready\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mwready\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mxready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda\\lib\\site-packages\\urllib3\\util\\wait.py\u001b[0m in \u001b[0;36m_retry_on_intr\u001b[1;34m(fn, timeout)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Modern Python, that retries syscalls by default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_retry_on_intr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# Old and broken Pythons.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "consumer_key = 'e6a6AL8uzdrq0rk8gAUpkf9Am'\n",
    "consumer_secret = 'lQ6qhk64Ai8rdjC2Ba5lMLAaUk5dfZQog0gVwUXkcgk9j5e5eU'\n",
    "access_token = '367199610-hYrg1EKMN8k3gzKibErKzQMzIP8viYS1l204yPKc'\n",
    "access_token_secret = 'HAo8dEOfosISGRiExd07ILr8KToL3zphpXfqomLW5e1ew'\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "#Set up the listener. The 'wait_on_rate_limit=True' is needed to help with Twitter API rate limiting.\n",
    "listener = StreamListener(api=tweepy.API(wait_on_rate_limit=True)) \n",
    "streamer = tweepy.Stream(auth=auth, listener=listener)\n",
    "tags = ['#medicaid','#medicare','#usmedicalinsurance','#usinsurance','medic aid','medicare','medicaid','medic care']\n",
    "print(\"Tracking: \" + str(tags))\n",
    "streamer.filter(track=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Tables in AWS Cloud  from Python & Loading Data\n",
    "\n",
    "We move to next step of creating the tables in our AWS Cloud setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "#the sqlalchemy package is used to connect python to rds and create tables in the aws rds\n",
    "engine = create_engine('mysql://admini:dmdd12345@dmdd.cep3r0xwloxj.us-east-21.rds.amazonaws.com/aws_insurance',encoding=\"utf-8\")\n",
    "#loading the Payment Table\n",
    "sql.to_sql(payment, con=engine, name='payment', \n",
    "                if_exists='replace',index = False)\n",
    "#loading the Claims Table\n",
    "sql.to_sql(claims, con=engine, name='claims', \n",
    "                if_exists='replace',index = False)\n",
    "#loading the Insurance Providers Table\n",
    "sql.to_sql(insu_provider, con=engine, name='insuranceprovider', \n",
    "                if_exists='replace',index = False)\n",
    "#loading the Policy Table\n",
    "sql.to_sql(policy, con=engine, name='policy', \n",
    "                if_exists='replace',index = False)\n",
    "#loading the Customer Table\n",
    "sql.to_sql(customer, con=engine, name='customer', \n",
    "                if_exists='replace',index = False)\n",
    "#loading the Customer Address Table\n",
    "sql.to_sql(customer_address, con=engine, name='customer_address', \n",
    "                if_exists='replace',index = False)\n",
    "ins_new = ins.rename(columns={'Plan ID ': 'Plan ID'})\n",
    "#loading the RAW CSV into Table\n",
    "sql.to_sql(ins_new, con=engine, name='insurance', \n",
    "                if_exists='replace',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be collecting twitter data of Issuers. We will be storing the names of the Issuer in an array object so that we can pass it to the twitter API to get the corresponding details of the issuer such as tweets, location, description of the company, tweets, number of followers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69 insurance providers. We will be collecting more information of the insurance providers using the Twitter API and storing it in the MySQL \n"
     ]
    }
   ],
   "source": [
    "#checking for the Hastags if they contains any Insurance Provider related tags\n",
    "issuer_names = insu_provider['Issuer_Name'].tolist()\n",
    "print ('There are {} insurance providers. We will be collecting more information of the insurance providers using the Twitter API and storing it in the MySQL '.format(len(issuer_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to Twitter\n",
    "consumer_key = 'e6a6AL8uzdrq0rk8gAUpkf9Am'\n",
    "consumer_secret = 'lQ6qhk64Ai8rdjC2Ba5lMLAaUk5dfZQog0gVwUXkcgk9j5e5eU'\n",
    "access_token = '367199610-hYrg1EKMN8k3gzKibErKzQMzIP8viYS1l204yPKc'\n",
    "access_token_secret = 'HAo8dEOfosISGRiExd07ILr8KToL3zphpXfqomLW5e1ew'\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "#Set up the listener. The 'wait_on_rate_limit=True' is needed to help with Twitter API rate limiting.\n",
    "listener = StreamListener(api=tweepy.API(wait_on_rate_limit=True)) \n",
    "streamer = tweepy.Stream(auth=auth, listener=listener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering the Twitter User table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we use the tweepy package to scrape the twitter user data directly from twitter\n",
    "verified = []\n",
    "twitter_id = []\n",
    "tname = []\n",
    "user_name = []\n",
    "location = []\n",
    "url = []\n",
    "followers_count = []\n",
    "statuses_count = []\n",
    "provider_id = []\n",
    "api = tweepy.API(auth)\n",
    "for name in issuer_names:\n",
    "    provider = insu_provider.loc[(insu_provider['Issuer_Name'] == name),'Provider_ID'].tolist()[0]\n",
    "    user = api.search_users(name)\n",
    "    if len(user) > 0 :\n",
    "        provider_id.append(provider)\n",
    "        verified.append(user[0].verified)\n",
    "        twitter_id.append(user[0].id)\n",
    "        tname.append(user[0].name)\n",
    "        user_name.append(user[0].screen_name)\n",
    "        location.append(user[0].location)\n",
    "        url.append(user[0].url)\n",
    "        followers_count.append(user[0].followers_count)\n",
    "        statuses_count.append(user[0].statuses_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Schema for the Twitter User Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_user = pd.DataFrame(columns = ['Twitter_ID', 'Name','Username', 'Verified',\n",
    "                                  'Location','url','No_of_Followers','No_of_Tweets','Provider_ID'])\n",
    "#assigning data to the schema\n",
    "tw_user['Twitter_ID'] = twitter_id\n",
    "tw_user['Name'] = tname\n",
    "tw_user['Username'] = user_name\n",
    "tw_user['Verified'] = verified\n",
    "tw_user['Location'] = location\n",
    "tw_user['url'] = url\n",
    "tw_user['No_of_Followers'] = followers_count\n",
    "tw_user['No_of_Tweets'] = statuses_count\n",
    "tw_user['Provider_ID'] = provider_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter User Table:\n",
    "\n",
    "Loading the scrapped user into Twitter table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.to_sql(tw_user, con=engine, name='provider_twitter', \n",
    "                if_exists='replace',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Username</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Location</th>\n",
       "      <th>url</th>\n",
       "      <th>No_of_Followers</th>\n",
       "      <th>No_of_Tweets</th>\n",
       "      <th>Provider_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>849775556</td>\n",
       "      <td>Health Options</td>\n",
       "      <td>CmtyHlthOptns</td>\n",
       "      <td>False</td>\n",
       "      <td>Lewiston, Maine</td>\n",
       "      <td>http://t.co/PPlbfyzSyj</td>\n",
       "      <td>602</td>\n",
       "      <td>3741</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>467554336</td>\n",
       "      <td>Anthem BCBS News</td>\n",
       "      <td>AnthemBCBS_News</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>http://t.co/8eY95I0HOl</td>\n",
       "      <td>3372</td>\n",
       "      <td>9415</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>573918122</td>\n",
       "      <td>Quartz</td>\n",
       "      <td>qz</td>\n",
       "      <td>True</td>\n",
       "      <td>The World</td>\n",
       "      <td>https://t.co/gLfIrRbtbb</td>\n",
       "      <td>388622</td>\n",
       "      <td>176897</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27922157</td>\n",
       "      <td>AMA</td>\n",
       "      <td>AmerMedicalAssn</td>\n",
       "      <td>True</td>\n",
       "      <td>Chicago/Washington D.C.</td>\n",
       "      <td>http://t.co/MEg0g5QqL2</td>\n",
       "      <td>722458</td>\n",
       "      <td>27748</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20519602</td>\n",
       "      <td>FirstCareHealthPlans</td>\n",
       "      <td>firstcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas</td>\n",
       "      <td>http://t.co/jK5HXsqTnu</td>\n",
       "      <td>298</td>\n",
       "      <td>1022</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Twitter_ID                  Name         Username  Verified  \\\n",
       "0   849775556        Health Options    CmtyHlthOptns     False   \n",
       "1   467554336      Anthem BCBS News  AnthemBCBS_News     False   \n",
       "2   573918122                Quartz               qz      True   \n",
       "3    27922157                   AMA  AmerMedicalAssn      True   \n",
       "4    20519602  FirstCareHealthPlans        firstcare     False   \n",
       "\n",
       "                  Location                      url  No_of_Followers  \\\n",
       "0          Lewiston, Maine   http://t.co/PPlbfyzSyj              602   \n",
       "1                            http://t.co/8eY95I0HOl             3372   \n",
       "2                The World  https://t.co/gLfIrRbtbb           388622   \n",
       "3  Chicago/Washington D.C.   http://t.co/MEg0g5QqL2           722458   \n",
       "4                    Texas   http://t.co/jK5HXsqTnu              298   \n",
       "\n",
       "   No_of_Tweets  Provider_ID  \n",
       "0          3741          202  \n",
       "1          9415          203  \n",
       "2        176897          205  \n",
       "3         27748          206  \n",
       "4          1022          209  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapping the Tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "#we use the twitter package again to scrap the twitter user tweets  data\n",
    "api = tweepy.API(auth)\n",
    "tw_id = []\n",
    "twt_id = []\n",
    "twt_text = []\n",
    "no_retweets = []\n",
    "fav_count = []\n",
    "j = 0\n",
    "#capturing the user data in real-time\n",
    "for scrname in user_name:\n",
    "    try:\n",
    "        tweets = api.user_timeline(screen_name=scrname, count=10)\n",
    "    except:\n",
    "        pass\n",
    "    for tweet in tweets:\n",
    "        tw_id.append(tweet.user.id)\n",
    "        twt_id.append(tweet.id)\n",
    "        twt_text.append(tweet.text)\n",
    "        no_retweets.append(tweet.retweet_count)\n",
    "        fav_count.append(tweet.favorite_count)\n",
    "    j +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets Table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Schema for Tweets Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ = pd.DataFrame(columns = ['Tweet_ID','Twitter_ID', 'Text','No_of Retweets', 'Favourites_Count'])\n",
    "tweets_['Tweet_ID'] = twt_id\n",
    "tweets_['Twitter_ID'] = tw_id\n",
    "tweets_['Text'] = twt_text\n",
    "tweets_['No_of_Retweets'] = no_retweets\n",
    "tweets_['Favourites_Count'] = fav_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection_string = f\"admini:dmdd1234@dmdd.cep3r0xwloxj.us-east-2.rds.amazonaws.com:3306/proj_insurance?charset=utf8\"\n",
    "#engine = create_engine(f'mysql://{connection_string}')\n",
    "engine = create_engine('mysql://admini:dmdd12345@dmdd.cep3r0xwloxj.us-east-21.rds.amazonaws.com/aws_insurance?charset=utf8')\n",
    "#for security purpose we have masked the url connection to aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Tweets table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.to_sql(tweets_, con=engine, name='tweets', \n",
    "                if_exists='replace',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Structure of all the Tables for our Insurance Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider_ID</th>\n",
       "      <th>Issuer_Name</th>\n",
       "      <th>HIOS_Issuer_ID</th>\n",
       "      <th>Metal_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>CareSource Georgia Co.</td>\n",
       "      <td>60224</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>Community Health Options</td>\n",
       "      <td>33653</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>203</td>\n",
       "      <td>Anthem Blue Cross and Blue Shield</td>\n",
       "      <td>29276</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>204</td>\n",
       "      <td>Health Alliance Medical Plans, Inc.</td>\n",
       "      <td>20129</td>\n",
       "      <td>Catastrophic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>205</td>\n",
       "      <td>Quartz</td>\n",
       "      <td>37833</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider_ID                          Issuer_Name  HIOS_Issuer_ID  \\\n",
       "0          201               CareSource Georgia Co.           60224   \n",
       "1          202             Community Health Options           33653   \n",
       "2          203    Anthem Blue Cross and Blue Shield           29276   \n",
       "3          204  Health Alliance Medical Plans, Inc.           20129   \n",
       "4          205                               Quartz           37833   \n",
       "\n",
       "    Metal_Level  \n",
       "0        Silver  \n",
       "1        Silver  \n",
       "2        Silver  \n",
       "3  Catastrophic  \n",
       "4        Silver  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insu_provider.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plan_ID</th>\n",
       "      <th>Medicaid_Enrollment</th>\n",
       "      <th>Medicaid_Enrollment_ID</th>\n",
       "      <th>Medicare_Enrollment_ID</th>\n",
       "      <th>Plan_Marketing_Name</th>\n",
       "      <th>Plan_Type</th>\n",
       "      <th>Provider_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60224GA0020005</td>\n",
       "      <td>False</td>\n",
       "      <td>9935517.0</td>\n",
       "      <td>294284</td>\n",
       "      <td>CareSource Marketplace Low Deductible Silver D...</td>\n",
       "      <td>HMO</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33653ME0050002</td>\n",
       "      <td>True</td>\n",
       "      <td>5727510.0</td>\n",
       "      <td>2118300</td>\n",
       "      <td>Community Advance PPO</td>\n",
       "      <td>PPO</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29276OH0920418</td>\n",
       "      <td>True</td>\n",
       "      <td>1220788.0</td>\n",
       "      <td>1181014</td>\n",
       "      <td>Anthem Silver Pathway X HMO 10 for HSA</td>\n",
       "      <td>HMO</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20129IL0330020</td>\n",
       "      <td>True</td>\n",
       "      <td>2748165.0</td>\n",
       "      <td>587780</td>\n",
       "      <td>HMO 8150 Elite Catastrophic</td>\n",
       "      <td>HMO</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>37833WI0380028</td>\n",
       "      <td>False</td>\n",
       "      <td>4123280.0</td>\n",
       "      <td>499753</td>\n",
       "      <td>Quartz One Silver I302 with Dental</td>\n",
       "      <td>HMO</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Plan_ID  Medicaid_Enrollment  Medicaid_Enrollment_ID  \\\n",
       "0  60224GA0020005                False               9935517.0   \n",
       "1  33653ME0050002                 True               5727510.0   \n",
       "2  29276OH0920418                 True               1220788.0   \n",
       "3  20129IL0330020                 True               2748165.0   \n",
       "4  37833WI0380028                False               4123280.0   \n",
       "\n",
       "   Medicare_Enrollment_ID                                Plan_Marketing_Name  \\\n",
       "0                  294284  CareSource Marketplace Low Deductible Silver D...   \n",
       "1                 2118300                              Community Advance PPO   \n",
       "2                 1181014             Anthem Silver Pathway X HMO 10 for HSA   \n",
       "3                  587780                        HMO 8150 Elite Catastrophic   \n",
       "4                  499753                 Quartz One Silver I302 with Dental   \n",
       "\n",
       "  Plan_Type  Provider_ID  \n",
       "0       HMO          201  \n",
       "1       PPO          202  \n",
       "2       HMO          203  \n",
       "3       HMO          204  \n",
       "4       HMO          205  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim ID</th>\n",
       "      <th>Plan_ID</th>\n",
       "      <th>Umbrella_Limit</th>\n",
       "      <th>Total_Claim_Amount</th>\n",
       "      <th>Report_Available</th>\n",
       "      <th>Claim-ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60224GA0020005</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>11310</td>\n",
       "      <td>?</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33653ME0050002</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>108710</td>\n",
       "      <td>?</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29276OH0920418</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>2690</td>\n",
       "      <td>YES</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20129IL0330020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>NO</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37833WI0380028</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>71240</td>\n",
       "      <td>?</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Claim ID         Plan_ID  Umbrella_Limit  Total_Claim_Amount  \\\n",
       "0      NaN  60224GA0020005       1000000.0               11310   \n",
       "1      NaN  33653ME0050002       2000000.0              108710   \n",
       "2      NaN  29276OH0920418       2000000.0                2690   \n",
       "3      NaN  20129IL0330020             0.0                1500   \n",
       "4      NaN  37833WI0380028       1000000.0               71240   \n",
       "\n",
       "  Report_Available  Claim-ID  \n",
       "0                ?       601  \n",
       "1                ?       602  \n",
       "2              YES       603  \n",
       "3               NO       604  \n",
       "4                ?       605  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>children</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>family_history</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>Plan_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>8091-TTVAX</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>176</td>\n",
       "      <td>60224GA0020005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0280-XJGEX</td>\n",
       "      <td>56</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>33653ME0050002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5129-JLPIS</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>169</td>\n",
       "      <td>29276OH0920418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3655-SNQYZ</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>89</td>\n",
       "      <td>20129IL0330020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>8191-XWSZG</td>\n",
       "      <td>52</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>85</td>\n",
       "      <td>37833WI0380028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customerID  age     sex  children  SeniorCitizen family_history  \\\n",
       "12  8091-TTVAX   23    male         0              0            Yes   \n",
       "13  0280-XJGEX   56  female         0              0             No   \n",
       "14  5129-JLPIS   27    male         0              0             No   \n",
       "15  3655-SNQYZ   19    male         1              0             No   \n",
       "16  8191-XWSZG   52  female         1              0            Yes   \n",
       "\n",
       "    months_as_customer         Plan_ID  \n",
       "12                 176  60224GA0020005  \n",
       "13                  79  33653ME0050002  \n",
       "14                 169  29276OH0920418  \n",
       "15                  89  20129IL0330020  \n",
       "16                  85  37833WI0380028  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address_ID</th>\n",
       "      <th>Number</th>\n",
       "      <th>Street</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "      <th>customerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>901</td>\n",
       "      <td>26</td>\n",
       "      <td>Magnolia Ln</td>\n",
       "      <td>NY</td>\n",
       "      <td>southwest</td>\n",
       "      <td>8091-TTVAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>902</td>\n",
       "      <td>61</td>\n",
       "      <td>Highview Ter</td>\n",
       "      <td>NC</td>\n",
       "      <td>southeast</td>\n",
       "      <td>0280-XJGEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>903</td>\n",
       "      <td>878</td>\n",
       "      <td>Chamberlain Hwy</td>\n",
       "      <td>MA</td>\n",
       "      <td>southeast</td>\n",
       "      <td>5129-JLPIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>904</td>\n",
       "      <td>782</td>\n",
       "      <td>Kensington Rd</td>\n",
       "      <td>IA</td>\n",
       "      <td>southwest</td>\n",
       "      <td>3655-SNQYZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>905</td>\n",
       "      <td>34</td>\n",
       "      <td>Magnolia Ln</td>\n",
       "      <td>CA</td>\n",
       "      <td>northeast</td>\n",
       "      <td>8191-XWSZG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Address_ID  Number           Street State     Region  customerID\n",
       "12         901      26      Magnolia Ln    NY  southwest  8091-TTVAX\n",
       "13         902      61     Highview Ter    NC  southeast  0280-XJGEX\n",
       "14         903     878  Chamberlain Hwy    MA  southeast  5129-JLPIS\n",
       "15         904     782    Kensington Rd    IA  southwest  3655-SNQYZ\n",
       "16         905      34      Magnolia Ln    CA  northeast  8191-XWSZG"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_address.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Payment_ID</th>\n",
       "      <th>Plan_ID</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Enrollment_Charges</th>\n",
       "      <th>Average_Monthly_Tax_Credit</th>\n",
       "      <th>customerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>60224GA0020005</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>1826.84</td>\n",
       "      <td>$265</td>\n",
       "      <td>8091-TTVAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>33653ME0050002</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>11090.72</td>\n",
       "      <td>$237</td>\n",
       "      <td>0280-XJGEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>29276OH0920418</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>39611.76</td>\n",
       "      <td>$259</td>\n",
       "      <td>5129-JLPIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>304</td>\n",
       "      <td>20129IL0330020</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>1837.24</td>\n",
       "      <td>$307</td>\n",
       "      <td>3655-SNQYZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>305</td>\n",
       "      <td>37833WI0380028</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>10797.34</td>\n",
       "      <td>$247</td>\n",
       "      <td>8191-XWSZG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Payment_ID         Plan_ID             Payment_Method  Enrollment_Charges  \\\n",
       "0         301  60224GA0020005    Credit card (automatic)             1826.84   \n",
       "1         302  33653ME0050002  Bank transfer (automatic)            11090.72   \n",
       "2         303  29276OH0920418           Electronic check            39611.76   \n",
       "3         304  20129IL0330020    Credit card (automatic)             1837.24   \n",
       "4         305  37833WI0380028               Mailed check            10797.34   \n",
       "\n",
       "  Average_Monthly_Tax_Credit  customerID  \n",
       "0                      $265   8091-TTVAX  \n",
       "1                      $237   0280-XJGEX  \n",
       "2                      $259   5129-JLPIS  \n",
       "3                      $307   3655-SNQYZ  \n",
       "4                      $247   8191-XWSZG  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Username</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Location</th>\n",
       "      <th>url</th>\n",
       "      <th>No_of_Followers</th>\n",
       "      <th>No_of_Tweets</th>\n",
       "      <th>Provider_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>849775556</td>\n",
       "      <td>Health Options</td>\n",
       "      <td>CmtyHlthOptns</td>\n",
       "      <td>False</td>\n",
       "      <td>Lewiston, Maine</td>\n",
       "      <td>http://t.co/PPlbfyzSyj</td>\n",
       "      <td>602</td>\n",
       "      <td>3741</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>467554336</td>\n",
       "      <td>Anthem BCBS News</td>\n",
       "      <td>AnthemBCBS_News</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>http://t.co/8eY95I0HOl</td>\n",
       "      <td>3372</td>\n",
       "      <td>9415</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>573918122</td>\n",
       "      <td>Quartz</td>\n",
       "      <td>qz</td>\n",
       "      <td>True</td>\n",
       "      <td>The World</td>\n",
       "      <td>https://t.co/gLfIrRbtbb</td>\n",
       "      <td>388622</td>\n",
       "      <td>176897</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27922157</td>\n",
       "      <td>AMA</td>\n",
       "      <td>AmerMedicalAssn</td>\n",
       "      <td>True</td>\n",
       "      <td>Chicago/Washington D.C.</td>\n",
       "      <td>http://t.co/MEg0g5QqL2</td>\n",
       "      <td>722458</td>\n",
       "      <td>27748</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20519602</td>\n",
       "      <td>FirstCareHealthPlans</td>\n",
       "      <td>firstcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas</td>\n",
       "      <td>http://t.co/jK5HXsqTnu</td>\n",
       "      <td>298</td>\n",
       "      <td>1022</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Twitter_ID                  Name         Username  Verified  \\\n",
       "0   849775556        Health Options    CmtyHlthOptns     False   \n",
       "1   467554336      Anthem BCBS News  AnthemBCBS_News     False   \n",
       "2   573918122                Quartz               qz      True   \n",
       "3    27922157                   AMA  AmerMedicalAssn      True   \n",
       "4    20519602  FirstCareHealthPlans        firstcare     False   \n",
       "\n",
       "                  Location                      url  No_of_Followers  \\\n",
       "0          Lewiston, Maine   http://t.co/PPlbfyzSyj              602   \n",
       "1                            http://t.co/8eY95I0HOl             3372   \n",
       "2                The World  https://t.co/gLfIrRbtbb           388622   \n",
       "3  Chicago/Washington D.C.   http://t.co/MEg0g5QqL2           722458   \n",
       "4                    Texas   http://t.co/jK5HXsqTnu              298   \n",
       "\n",
       "   No_of_Tweets  Provider_ID  \n",
       "0          3741          202  \n",
       "1          9415          203  \n",
       "2        176897          205  \n",
       "3         27748          206  \n",
       "4          1022          209  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_user.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Twitter_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>No_of Retweets</th>\n",
       "      <th>Favourites_Count</th>\n",
       "      <th>No_of_Retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1253751279068864515</td>\n",
       "      <td>849775556</td>\n",
       "      <td>We are partnering with @PortlandChamber and ot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1253385931744215043</td>\n",
       "      <td>849775556</td>\n",
       "      <td>#leadershipskills https://t.co/6WD7eUprGl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1233557662354300935</td>\n",
       "      <td>849775556</td>\n",
       "      <td>Are you worried about the spread of the corona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1204443894957649927</td>\n",
       "      <td>849775556</td>\n",
       "      <td>RT @MTUG_Maine: Please join us online! WED 12/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1169335101026709505</td>\n",
       "      <td>849775556</td>\n",
       "      <td>@JMHeffren Please contact Member Services at 8...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet_ID  Twitter_ID  \\\n",
       "0  1253751279068864515   849775556   \n",
       "1  1253385931744215043   849775556   \n",
       "2  1233557662354300935   849775556   \n",
       "3  1204443894957649927   849775556   \n",
       "4  1169335101026709505   849775556   \n",
       "\n",
       "                                                Text No_of Retweets  \\\n",
       "0  We are partnering with @PortlandChamber and ot...            NaN   \n",
       "1          #leadershipskills https://t.co/6WD7eUprGl            NaN   \n",
       "2  Are you worried about the spread of the corona...            NaN   \n",
       "3  RT @MTUG_Maine: Please join us online! WED 12/...            NaN   \n",
       "4  @JMHeffren Please contact Member Services at 8...            NaN   \n",
       "\n",
       "   Favourites_Count  No_of_Retweets  \n",
       "0                 0               0  \n",
       "1                 0               0  \n",
       "2                 0               0  \n",
       "3                 0               2  \n",
       "4                 0               0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = MySQLdb.connect(host=HOST, port=3306, user=USER, passwd=PASSWD, db=DATABASE)\n",
    "cursor=conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((Decimal('38.9108'),),)\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 1: Average age of all the customers \n",
    "cursor.execute(\"\"\"SELECT AVG(Age) FROM customer;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('8091-TTVAX',),)\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 2: Name of the Customer who had the highest Enrollement Charges\n",
    "cursor.execute(\"\"\"select CustomerID from payment order by 'Enrollment Charges' desc limit 1;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('RT @CoverAlabama: Hundreds of thousands of Alabamians are counting on us '\n",
      "  'for access to affordable health insurance. We MUST remain persisteâ€¦',\n",
      "  datetime.datetime(2020, 4, 24, 22, 13, 41)),\n",
      " ('Florida Senator has 14 felony counts stemming from medicare insurance '\n",
      "  'scams... yet old people on medicare vote forâ€¦ https://t.co/7RTglvMrW7',\n",
      "  datetime.datetime(2020, 4, 24, 22, 22, 27)),\n",
      " ('?? If you have transitioned to Medicare off of commercial insurance and can '\n",
      "  'share tips, tricks, and watch-outs \\n'\n",
      "  '\\n'\n",
      "  '??â€¦ https://t.co/nioGrzkWXD',\n",
      "  datetime.datetime(2020, 4, 24, 22, 32, 49)),\n",
      " ('@Shill_Destroyer @scrowder This whole \"68,000 ppl die from no health '\n",
      "  'insurance\" line is pure bologna. Nobody NOBODYâ€¦ https://t.co/SPjiQpS8X6',\n",
      "  datetime.datetime(2020, 4, 24, 22, 33, 44)),\n",
      " ('@NshitThings @JoeBiden M4A is something Biden will never get.  He loves big '\n",
      "  'insurance it is the reason he wants theâ€¦ https://t.co/ranmTTqPMa',\n",
      "  datetime.datetime(2020, 4, 24, 22, 42, 31)),\n",
      " ('@ThottonMather He can enroll in Medicare if old enough. Insurance available '\n",
      "  'through COBRA. If furloughed, isnâ€™t comâ€¦ https://t.co/IN7geCakBp',\n",
      "  datetime.datetime(2020, 4, 24, 22, 45, 17)),\n",
      " ('9.2 million workers likely lost their employer-provided health insurance in '\n",
      "  'the past four weeks  and Nancy Pelosi hâ€¦ https://t.co/adKupk9QaI',\n",
      "  datetime.datetime(2020, 4, 24, 22, 49, 10)),\n",
      " ('RT @GoodTwitty: 9.2 million workers likely lost their employer-provided '\n",
      "  'health insurance in the past four weeks  and Nancy Pelosi has decidâ€¦',\n",
      "  datetime.datetime(2020, 4, 24, 22, 49, 42)),\n",
      " ('RT @GoodTwitty: 9.2 million workers likely lost their employer-provided '\n",
      "  'health insurance in the past four weeks  and Nancy Pelosi has decidâ€¦',\n",
      "  datetime.datetime(2020, 4, 24, 22, 50, 1)),\n",
      " ('RT @RoKhanna: An estimated 9 million Americans lost their health insurance '\n",
      "  'last month.\\n'\n",
      "  '\\n'\n",
      "  'This crisis has made it clear that health care shouâ€¦',\n",
      "  datetime.datetime(2020, 4, 24, 22, 50, 22)),\n",
      " ('If you recently lost your job-based health insurance but donâ€™t qualify for '\n",
      "  'Medicaid, you can likely sign up for disâ€¦ https://t.co/O9qkcHtbve',\n",
      "  datetime.datetime(2020, 4, 24, 22, 53, 10)),\n",
      " ('9.2 million workers likely lost their employer-provided health insurance in '\n",
      "  'the past four weeks  and Nancy Pelosi hâ€¦ https://t.co/nmiPtULpGY',\n",
      "  datetime.datetime(2020, 4, 24, 22, 53, 30)),\n",
      " ('RT @CoverAlabama: Hundreds of thousands of Alabamians are counting on us '\n",
      "  'for access to affordable health insurance. We MUST remain persisteâ€¦',\n",
      "  datetime.datetime(2020, 4, 24, 22, 59, 46)))\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 3: What are people saying about insurance ? # Select all hashtags included in all tweets about insurance.\n",
    "cursor.execute(\"\"\"select text, created_at from twitter where text like \"%insurance%\" order by created_at;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('CA',),)\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 4: Which State has the hieghtest number of Senior Citizens \n",
    "\n",
    "cursor.execute(\"\"\"select state from customer_address ca inner join customer c on ca.customerID = c.customerID\n",
    "where seniorcitizen !=  0 group by state order by count(*) desc limit 1;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Medica',),)\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 5: Which is the most popular Insurance Provider \n",
    "\n",
    "cursor.execute(\"\"\"select Issuer_Name from insuranceprovider ip inner join policy p on ip.provider_ID = p.provider_ID\n",
    "group by Issuer_Name order by count(*) desc limit 1;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((81,),)\n"
     ]
    }
   ],
   "source": [
    "#USE CASE 6: Number of Female Customers who have medicaid enrollement\n",
    "\n",
    "cursor.execute(\"\"\"select count(*) as Number_of_Female_Medcaid_Benifiters from policy p inner join customer c\n",
    "on p.plan_id = c.plan_id where c.sex like 'female' and Medicaid_Enrollment != 0;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('8091-TTVAX', 23, 'male', 26, 'Magnolia Ln', 'NY', 'southwest'),)\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 7: Customer details who recieves the highest Yearly Tax Credit \n",
    "\n",
    "cursor.execute(\"\"\"select c.customerID, c.age, c.sex, ca.number, ca.street, ca.state, ca.region from customer c\n",
    "inner join customer_address ca on c.customerID = ca.customerID inner join payment p on c.plan_id = p.plan_id\n",
    "order by (p.average_monthly_tax_credit * 12) desc limit 1;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('$294',),)\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 8: Average Monthly Tax credit for  ****** Policy \n",
    "\n",
    "cursor.execute(\"\"\"select average_monthly_tax_credit from payment p inner join policy po on p.plan_id = po.plan_id\n",
    "where po.plan_marketing_name like '%Oscar Classic Silver%';;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('CareSource Marketplace Low Deductible Silver Dental, Vision, & Fitness',),)\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 9: Which is the most popular insurance policy among the southwest region \n",
    "\n",
    "cursor.execute(\"\"\"select po.plan_marketing_name from policy po inner join customer c on po.plan_id = c.plan_id\n",
    "inner join customer_address ca on c.customerID = ca.customerID where ca.region like 'southwest' group by c.plan_id\n",
    "order by count(*) desc limit 1;;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Medica',),)\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 10: Which Insurance provider holds the heighest number of claims \n",
    "cursor.execute(\"\"\"select Issuer_Name from insuranceprovider ip inner join policy p on ip.provider_ID = p.provider_ID\n",
    "inner join claims c on p.plan_id = c.plan_id group by Issuer_Name order by count(*) desc limit 1;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((datetime.datetime(2020, 4, 24, 22, 52, 59), 3),\n",
      " (datetime.datetime(2020, 4, 24, 22, 15, 17), 3),\n",
      " (datetime.datetime(2020, 4, 24, 22, 41, 20), 3),\n",
      " (datetime.datetime(2020, 4, 24, 22, 25, 6), 3),\n",
      " (datetime.datetime(2020, 4, 24, 22, 31, 34), 3),\n",
      " (datetime.datetime(2020, 4, 24, 22, 53, 37), 2),\n",
      " (datetime.datetime(2020, 4, 24, 22, 55, 25), 2),\n",
      " (datetime.datetime(2020, 4, 24, 22, 56, 47), 2),\n",
      " (datetime.datetime(2020, 4, 24, 23, 0, 48), 2),\n",
      " (datetime.datetime(2020, 4, 24, 22, 36, 28), 2))\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 11: Number of top 10 latest tweets with date\n",
    "cursor.execute(\"\"\"SELECT created_at, COUNT(tweet_id) FROM twitter GROUP BY created_at ORDER BY COUNT(tweet_id) DESC LIMIT 10;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((\"RT @nationaltrust: We're aiming to open many of our gardens and parks for \"\n",
      "  'free during this difficult time, so the nation can use open spaceâ€¦',\n",
      "  1240056616264892419,\n",
      "  14161),\n",
      " ('RT @LouisianaGov: Part of our new normal will mean wearing a mask or '\n",
      "  'face-covering in public. Wearing a mask in public is just like holdingâ€¦',\n",
      "  1253359742052970498,\n",
      "  509),\n",
      " ('Do not ingest or #InjectDisinfectant products â€“ it will cause bodily harm. '\n",
      "  'Treatments for #COVID19 must be guided bâ€¦ https://t.co/YdjQmNZ70V',\n",
      "  1253756569831047169,\n",
      "  200),\n",
      " ('RT @DEAHQ: .@DEAHQ launches the #SecureYourMeds campaign, asking Americans '\n",
      "  'to keep prescription medications safe and secure until they canâ€¦',\n",
      "  1253358607107842048,\n",
      "  85),\n",
      " ('RT @OHAOregon: There are currently no medications or treatments that are '\n",
      "  'effective at preventing or treating #COVID19 and many of the homeâ€¦',\n",
      "  1253718059761598465,\n",
      "  80),\n",
      " ('RT @BishopStAlbans: A message from Bishop Alan to the people of the Diocese '\n",
      "  'of St Albans for Palm Sunday and Holy Week 2020. Please retweetâ€¦',\n",
      "  1246555500336029697,\n",
      "  46),\n",
      " ('RT @UofSCNursing: Coach Will Muschamp gives a special shout-out to the '\n",
      "  '#Gamecock Nursing nation. Forever To Thee! #UofSC \\n'\n",
      "  '@GamecocksOnlineâ€¦',\n",
      "  1253060113860104194,\n",
      "  32),\n",
      " ('RT @scdhec: Your health is important and so is the health of our planet. '\n",
      "  'Dispose properly of gloves, masks, cleaning supplies, and protectiâ€¦',\n",
      "  1252937746232029187,\n",
      "  27),\n",
      " ('RT @BarristerWilson: Dear Colleagues, in these troubling and uncertain '\n",
      "  'times, please remember to make use of the resources on the #wellbeinâ€¦',\n",
      "  1240055986318082048,\n",
      "  26),\n",
      " ('RT @scdhec: In the face of uncertainty, we can choose how we respond to '\n",
      "  'better care for our mental health. Find the balance that works forâ€¦',\n",
      "  1253709595144486914,\n",
      "  26))\n"
     ]
    }
   ],
   "source": [
    "# USE CASE 12: What social media users are like other social media users in your domain?  #here we look for the Tweet with highest number of retweets\n",
    "cursor.execute(\"\"\"select t.text, t.tweet_id, t.no_of_retweets from tweets t order by no_of_retweets desc limit 10;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Lyndsey de Mestre QC', 14161),\n",
      " ('Louisiana Blue Cross', 509),\n",
      " ('AMA', 200),\n",
      " ('Louisiana Blue Cross', 85),\n",
      " ('PacificSource', 80),\n",
      " ('Lyndsey de Mestre QC', 46),\n",
      " ('BCBSSC', 32),\n",
      " ('BCBSSC', 27),\n",
      " ('Lyndsey de Mestre QC', 26),\n",
      " ('BCBSSC', 26))\n"
     ]
    }
   ],
   "source": [
    "## USE CASE 13: What people, places or things are popular in your domain? # We can check the no. of retweets count of each text to determine the popular people in our domain\n",
    "\n",
    "cursor.execute(\"\"\"select pt.Name, t.no_of_retweets from tweets t inner join provider_twitter pt on t.twitter_id = pt.twitter_id\n",
    "order by no_of_retweets desc limit 10;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('AMA', 380),\n",
      " ('Kaiser Permanente', 39),\n",
      " ('Kaiser Permanente', 33),\n",
      " ('Kaiser Permanente', 25),\n",
      " ('AMA', 20),\n",
      " ('AMA', 17),\n",
      " ('AMA', 17),\n",
      " ('Arkansas Blue Cross and Blue Shield', 17),\n",
      " ('Kaiser Permanente', 14),\n",
      " ('CareSource', 12))\n"
     ]
    }
   ],
   "source": [
    "## USE CASE 14: Who is the most influencer to posts? \n",
    "cursor.execute(\"\"\"select pt.Name, t.Favourites_Count from provider_twitter pt inner join tweets t \n",
    "on pt.twitter_id = t.twitter_id where t.no_of_retweets !=0 and t.Favourites_Count !=0 group by t.text order by t.Favourites_Count DESC limit 10;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Community Health Options', 1),\n",
      " ('Anthem Blue Cross and Blue Shield', 1),\n",
      " ('Quartz', 1),\n",
      " ('Medica', 1),\n",
      " ('FirstCare Health Plans', 1),\n",
      " ('Molina Healthcare', 1),\n",
      " ('Blue Cross and Blue Shield of Texas', 1),\n",
      " ('CareSource', 1),\n",
      " ('Ambetter from MHS', 1),\n",
      " ('Bright Health', 1))\n"
     ]
    }
   ],
   "source": [
    "## USE CASE 15 : Number of tweets about each company \n",
    "cursor.execute(\"\"\"SELECT p.issuer_name, COUNT(pt.no_of_tweets) as 'Number of Tweets' FROM insuranceprovider p\n",
    "JOIN provider_twitter pt ON p.provider_id = pt.provider_id GROUP BY p.issuer_name ORDER BY COUNT(pt.no_of_tweets) DESC\n",
    "LIMIT 10;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('2080-SRCDE', 30, 'MS', 'northeast', 154740),\n",
      " ('6865-JZNKO', 59, 'IN', 'southeast', 133800),\n",
      " ('7233-PAHHL', 59, 'MN', 'northeast', 122500),\n",
      " ('6067-NGCEU', 35, 'PA', 'northwest', 116900),\n",
      " ('9167-APMXZ', 48, 'VA', 'southeast', 116900))\n"
     ]
    }
   ],
   "source": [
    "## USE CASE 16: Which customer has the hieghest Claim amount\n",
    "cursor.execute(\"\"\"select c.customerid, c.age, ca.state, ca.region, cl.total_claim_amount from customer c \n",
    "inner join customer_address ca on c.customerid = ca.customerid inner join claims cl on c.plan_id = cl.plan_id\n",
    "order by cl.total_claim_amount desc limit 5;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Medica',),\n",
      " ('Anthem Blue Cross and Blue Shield',),\n",
      " ('Ambetter from MHS',),\n",
      " ('Blue Cross and Blue Shield of Texas',),\n",
      " ('Blue Cross Blue Shield Healthcare Plan of Georgia',))\n"
     ]
    }
   ],
   "source": [
    "##  USE CASE 17: Which Insurance Has the highest number of reports missing \n",
    "cursor.execute(\"\"\"select p.issuer_name from insuranceprovider p inner join policy po on p.provider_id = po.provider_id\n",
    "inner join claims c on po.plan_id = c.plan_id and c.report_available like 'YES' group by p.issuer_name order by count(*) desc\n",
    "limit 5;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  USE CASE 18 :What social media users are like other social media users in your domain?\n",
    "\n",
    "cursor.execute(\"\"\"select twitter_id, name, username, location, no_of_followers, verified from provider_twitter;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Database:\n",
    "\n",
    "Database quering can be costly affair particulary when we are dealing with high number of joins and filter conditions. The more\n",
    "the number tables involved in producing the result the more the time is needed to query all the matching data. This can be impacting the performance and there are several ways to optimise a database.\n",
    "\n",
    "## Partitioning:\n",
    "\n",
    "Patitioning is the process of splitting tables by physically putting tables on individual disk drives.Doing so will allow the database to subdivided into smaller pieces thus queries shall access only a fraction of the data can run faster because there is fewer data to scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# Applying Partition to table\n",
    "cursor.execute(\"\"\"ALTER TABLE insuranceprovider PARTITION BY HASH(provider_id) PARTITIONS 6;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# Applying Partition to customer table\n",
    "cursor.execute(\"\"\"ALTER TABLE customer PARTITION BY HASH(age) PARTITIONS 6;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# Applying Partition to customer_address table\n",
    "cursor.execute(\"\"\"ALTER TABLE customer_address PARTITION BY HASH(address_id) PARTITIONS 6;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# Applying Partition to payment table\n",
    "cursor.execute(\"\"\"ALTER TABLE payment PARTITION BY HASH(payment_id) PARTITIONS 6;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"ALTER TABLE claims PARTITION BY HASH(`Claim-ID`) PARTITIONS 6;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing:\n",
    "\n",
    "The most effective and simplest way is to use the indexing.Indexes are columns that are applied on the table structure to speed up any action on the table, like select, update etc in the table. An best example is like that of an index in a book. Users wont be able to see the index but can see the perfomance imporved post applying the indexing.\n",
    "\n",
    "To make indexing even more optimised, only create indexes on columns that will be frequently searched against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Applying Index to Tables:\n",
    "cursor.execute(\"\"\"create index idx_provider on insuranceprovider (provider_id);\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"Capture.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since applying the indexing on the Insurance Provider table, executing of any queries that involving the indexed column shall be executed faster than before. Hence any operation that involves the indexed column like select, update insert shall all be better optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUDIT:\n",
    "\n",
    "AUDIT VALIDITY/ACCURACY:\n",
    "\tWe say data is accurate only when it is neat and with no null or junk values. Here we used dropna() function to drop all the if they data holds any null values.\n",
    "    \n",
    "AUDIT COMPLETNESS:\n",
    "  The database for an organization wherein we might be adding additional tables and columns depending on the real-world scenario. For now the database has been built in-par with the conceptual model.\n",
    "    \n",
    "AUDIT CONSISTENCY/UNIFORMITY:\n",
    "\tThe datasets which have been used in this assignment show a uniform relationship between each of the dataset since they are linked to each other by a common attribute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTIBUTORS :\n",
    "\n",
    "#### ASHWIN JOHN CHEMPOLIL, CRISPIN SUJITH CLETUS, VIGNESH THANIGAI SIVABALAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CITATIONS:\n",
    "\n",
    "Sources from where you have gained knowledge or used codes, data. It may include Web links, github links, code taken from somewhere etc.\n",
    "\n",
    "https://stackoverflow.com/questions/16476413/how-to-insert-pandas-dataframe-via-mysqlengine-into-database\n",
    "https://docs.sqlalchemy.org/en/13/core/engines.html\n",
    "https://stackoverflow.com/questions/43942357/pandas-to-sql-inserting-index\n",
    "https://pythondata.com/collecting-storing-tweets-python-mysql/\n",
    "https://github.com/nikbearbrown/INFO_6210/blob/master/Project/Jobs_DB_Project/IPYNB/MySQL.ipynb\n",
    "https://github.com/nikbearbrown/INFO_6210/blob/master/Project/Jobs_DB_Project/IPYNB/NoSQL-Project-Social-Media.ipynb\n",
    "https://www.alexkras.com/how-to-get-user-feed-with-twitter-api-and-python/\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html\n",
    "https://towardsdatascience.com/twitter-data-collection-tutorial-using-python-3267d7cfa93e\n",
    "https://stackoverflow.com/questions/34682828/extracting-specific-selected-columns-to-new-dataframe-as-a-copy\n",
    "\n",
    "\n",
    "<copyright 2019 mavi>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LICENSE\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2020 ASHWIN JOHN CHEMPOLIL, CRISPIN SUJITH CLETUS, VIGNESH THANIGAI SIVABALAN\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
